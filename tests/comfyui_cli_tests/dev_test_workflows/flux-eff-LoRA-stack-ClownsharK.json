{
  "51": {
    "inputs": {
      "samples": [
        "1027",
        0
      ],
      "vae": [
        "663",
        0
      ]
    },
    "class_type": "VAEDecode",
    "_meta": {
      "title": "VAE Decode"
    }
  },
  "663": {
    "inputs": {
      "vae_name": "ae.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "693": {
    "inputs": {
      "unet_name": "flux\\flux1-dev-fp8-e4m3fn.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    },
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Diffusion Model"
    }
  },
  "694": {
    "inputs": {
      "clip_name1": "flux\\t5xxl_fp8_e4m3fn_scaled.safetensors",
      "clip_name2": "flux\\Long-ViT-L-14-REG-TE-only-HF-format.safetensors",
      "type": "flux",
      "device": "default"
    },
    "class_type": "DualCLIPLoader",
    "_meta": {
      "title": "DualCLIPLoader"
    }
  },
  "725": {
    "inputs": {
      "dimensions": " 832 x 1216  (portrait)",
      "clip_scale": 1,
      "batch_size": 1
    },
    "class_type": "SDXL Empty Latent Image (rgthree)",
    "_meta": {
      "title": "Choose Preset Resolution"
    }
  },
  "1001": {
    "inputs": {
      "text": "oil painting, semi realistic, fantasy, anime style, solid color background, tall thin character, beautiful lush vibrant forest, backlighting, dramatic atmospheric glow, countless small tiny clumsy gentle spirits, great forest spirit, intricate highly detailed, natural fantastical elements, leaves flowers feathers, hair clothing, delicate translucent wings, gentle mystical business, forest secret heartbeat, branches arms, leaves hair, ethereal benevolent connection, natural world, deep abiding, magic, hushed reverence, wonder, mysticism, otherworldly aura, vibrant colors, bold brushstrokes, gradating background, blues emerald greens, slender athletic build, elegant arm, beckoning summoning, reverence awe, drinking in essence, character attire, mesmerizing blend, organic growth, R3alisticF, retr0grade90s, A digital anime artwork in the style of cklg, in the style of cksc,",
      "clip": [
        "1062",
        1
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "1015": {
    "inputs": {
      "backend": "inductor",
      "model": [
        "1016",
        0
      ]
    },
    "class_type": "TorchCompileModel",
    "_meta": {
      "title": "TorchCompileModel"
    }
  },
  "1016": {
    "inputs": {
      "sage_attention": "auto",
      "allow_compile": true,
      "model": [
        "693",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "1017": {
    "inputs": {
      "patch_order": "object_patch_first",
      "full_load": "auto",
      "model": [
        "1015",
        0
      ]
    },
    "class_type": "PatchModelPatcherOrder",
    "_meta": {
      "title": "Patch Model Patcher Order"
    }
  },
  "1027": {
    "inputs": {
      "eta": 0.5,
      "sampler_name": "linear/euler",
      "scheduler": "bong_tangent",
      "steps": 2,
      "steps_to_run": -1,
      "denoise": 1,
      "cfg": 1,
      "seed": [
        "1040",
        0
      ],
      "sampler_mode": "standard",
      "bongmath": true,
      "model": [
        "1034",
        0
      ],
      "positive": [
        "1031",
        0
      ],
      "negative": [
        "1028",
        0
      ],
      "latent_image": [
        "725",
        0
      ]
    },
    "class_type": "ClownsharKSampler_Beta",
    "_meta": {
      "title": "ClownsharKSampler"
    }
  },
  "1028": {
    "inputs": {
      "conditioning": [
        "1031",
        0
      ]
    },
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "ConditioningZeroOut"
    }
  },
  "1031": {
    "inputs": {
      "guidance": 3.5,
      "conditioning": [
        "1001",
        0
      ]
    },
    "class_type": "FluxGuidance",
    "_meta": {
      "title": "FluxGuidance"
    }
  },
  "1034": {
    "inputs": {
      "max_shift": 1.15,
      "base_shift": 0.5,
      "width": [
        "725",
        1
      ],
      "height": [
        "725",
        2
      ],
      "model": [
        "1062",
        0
      ]
    },
    "class_type": "ModelSamplingFlux",
    "_meta": {
      "title": "ModelSamplingFlux"
    }
  },
  "1040": {
    "inputs": {
      "seed": 684898030661856
    },
    "class_type": "Seed (rgthree)",
    "_meta": {
      "title": "Seed (rgthree)"
    }
  },
  "1062": {
    "inputs": {
      "model": [
        "1017",
        0
      ],
      "clip": [
        "694",
        0
      ],
      "lora_stack": [
        "1118",
        0
      ]
    },
    "class_type": "CR Apply LoRA Stack",
    "_meta": {
      "title": "ðŸ’Š CR Apply LoRA Stack"
    }
  },
  "1117": {
    "inputs": {
      "filename_prefix": "Test\\flux-eff-LoRA-stack-ClownsharK",
      "sampler_selection_method": "Farthest",
      "sampler_selection_node_id": 0,
      "file_format": "png",
      "lossless_webp": true,
      "quality": 100,
      "max_jpeg_exif_kb": 60,
      "save_workflow_json": false,
      "add_counter_to_filename": true,
      "civitai_sampler": true,
      "guidance_as_cfg": true,
      "save_workflow_image": true,
      "include_lora_summary": false,
      "suppress_missing_class_log": false,
      "model_hash_log": "none",
      "images": [
        "51",
        0
      ]
    },
    "class_type": "SaveImageWithMetaDataUniversal",
    "_meta": {
      "title": "Save Image w/ Metadata Universal"
    }
  },
  "1118": {
    "inputs": {
      "input_mode": "advanced",
      "lora_count": 3,
      "lora_name_1": "flux\\artstyle\\style\\Fluorescentizer FLUX B.safetensors",
      "lora_wt_1": 1,
      "model_str_1": 0.3,
      "clip_str_1": 0.22,
      "lora_name_2": "flux\\artstyle\\style\\fantasy\\FluxProtectorsOfNature.safetensors",
      "lora_wt_2": 1,
      "model_str_2": 0.6,
      "clip_str_2": 0.35,
      "lora_name_3": "flux\\artstyle\\style\\DND_COLORBOYZ_FG_FLUX_REMUS_Lora.safetensors",
      "lora_wt_3": 1,
      "model_str_3": 0.7,
      "clip_str_3": 0.44,
      "lora_name_4": "None",
      "lora_wt_4": 1,
      "model_str_4": 1,
      "clip_str_4": 1,
      "lora_name_5": "None",
      "lora_wt_5": 1,
      "model_str_5": 1,
      "clip_str_5": 1,
      "lora_name_6": "None",
      "lora_wt_6": 1,
      "model_str_6": 1,
      "clip_str_6": 1,
      "lora_name_7": "None",
      "lora_wt_7": 1,
      "model_str_7": 1,
      "clip_str_7": 1,
      "lora_name_8": "None",
      "lora_wt_8": 1,
      "model_str_8": 1,
      "clip_str_8": 1,
      "lora_name_9": "None",
      "lora_wt_9": 1,
      "model_str_9": 1,
      "clip_str_9": 1,
      "lora_name_10": "None",
      "lora_wt_10": 1,
      "model_str_10": 1,
      "clip_str_10": 1,
      "lora_name_11": "None",
      "lora_wt_11": 1,
      "model_str_11": 1,
      "clip_str_11": 1,
      "lora_name_12": "None",
      "lora_wt_12": 1,
      "model_str_12": 1,
      "clip_str_12": 1,
      "lora_name_13": "None",
      "lora_wt_13": 1,
      "model_str_13": 1,
      "clip_str_13": 1,
      "lora_name_14": "None",
      "lora_wt_14": 1,
      "model_str_14": 1,
      "clip_str_14": 1,
      "lora_name_15": "None",
      "lora_wt_15": 1,
      "model_str_15": 1,
      "clip_str_15": 1,
      "lora_name_16": "None",
      "lora_wt_16": 1,
      "model_str_16": 1,
      "clip_str_16": 1,
      "lora_name_17": "None",
      "lora_wt_17": 1,
      "model_str_17": 1,
      "clip_str_17": 1,
      "lora_name_18": "None",
      "lora_wt_18": 1,
      "model_str_18": 1,
      "clip_str_18": 1,
      "lora_name_19": "None",
      "lora_wt_19": 1,
      "model_str_19": 1,
      "clip_str_19": 1,
      "lora_name_20": "None",
      "lora_wt_20": 1,
      "model_str_20": 1,
      "clip_str_20": 1,
      "lora_name_21": "None",
      "lora_wt_21": 1,
      "model_str_21": 1,
      "clip_str_21": 1,
      "lora_name_22": "None",
      "lora_wt_22": 1,
      "model_str_22": 1,
      "clip_str_22": 1,
      "lora_name_23": "None",
      "lora_wt_23": 1,
      "model_str_23": 1,
      "clip_str_23": 1,
      "lora_name_24": "None",
      "lora_wt_24": 1,
      "model_str_24": 1,
      "clip_str_24": 1,
      "lora_name_25": "None",
      "lora_wt_25": 1,
      "model_str_25": 1,
      "clip_str_25": 1,
      "lora_name_26": "None",
      "lora_wt_26": 1,
      "model_str_26": 1,
      "clip_str_26": 1,
      "lora_name_27": "None",
      "lora_wt_27": 1,
      "model_str_27": 1,
      "clip_str_27": 1,
      "lora_name_28": "None",
      "lora_wt_28": 1,
      "model_str_28": 1,
      "clip_str_28": 1,
      "lora_name_29": "None",
      "lora_wt_29": 1,
      "model_str_29": 1,
      "clip_str_29": 1,
      "lora_name_30": "None",
      "lora_wt_30": 1,
      "model_str_30": 1,
      "clip_str_30": 1,
      "lora_name_31": "None",
      "lora_wt_31": 1,
      "model_str_31": 1,
      "clip_str_31": 1,
      "lora_name_32": "None",
      "lora_wt_32": 1,
      "model_str_32": 1,
      "clip_str_32": 1,
      "lora_name_33": "None",
      "lora_wt_33": 1,
      "model_str_33": 1,
      "clip_str_33": 1,
      "lora_name_34": "None",
      "lora_wt_34": 1,
      "model_str_34": 1,
      "clip_str_34": 1,
      "lora_name_35": "None",
      "lora_wt_35": 1,
      "model_str_35": 1,
      "clip_str_35": 1,
      "lora_name_36": "None",
      "lora_wt_36": 1,
      "model_str_36": 1,
      "clip_str_36": 1,
      "lora_name_37": "None",
      "lora_wt_37": 1,
      "model_str_37": 1,
      "clip_str_37": 1,
      "lora_name_38": "None",
      "lora_wt_38": 1,
      "model_str_38": 1,
      "clip_str_38": 1,
      "lora_name_39": "None",
      "lora_wt_39": 1,
      "model_str_39": 1,
      "clip_str_39": 1,
      "lora_name_40": "None",
      "lora_wt_40": 1,
      "model_str_40": 1,
      "clip_str_40": 1,
      "lora_name_41": "None",
      "lora_wt_41": 1,
      "model_str_41": 1,
      "clip_str_41": 1,
      "lora_name_42": "None",
      "lora_wt_42": 1,
      "model_str_42": 1,
      "clip_str_42": 1,
      "lora_name_43": "None",
      "lora_wt_43": 1,
      "model_str_43": 1,
      "clip_str_43": 1,
      "lora_name_44": "None",
      "lora_wt_44": 1,
      "model_str_44": 1,
      "clip_str_44": 1,
      "lora_name_45": "None",
      "lora_wt_45": 1,
      "model_str_45": 1,
      "clip_str_45": 1,
      "lora_name_46": "None",
      "lora_wt_46": 1,
      "model_str_46": 1,
      "clip_str_46": 1,
      "lora_name_47": "None",
      "lora_wt_47": 1,
      "model_str_47": 1,
      "clip_str_47": 1,
      "lora_name_48": "None",
      "lora_wt_48": 1,
      "model_str_48": 1,
      "clip_str_48": 1,
      "lora_name_49": "None",
      "lora_wt_49": 1,
      "model_str_49": 1,
      "clip_str_49": 1,
      "lora_name_50": "None",
      "lora_wt_50": 1,
      "model_str_50": 1,
      "clip_str_50": 1
    },
    "class_type": "LoRA Stacker",
    "_meta": {
      "title": "LoRA Stacker"
    }
  }
}