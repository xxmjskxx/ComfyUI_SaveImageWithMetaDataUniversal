#!/usr/bin/env python3
"""
Metadata Validation Script for ComfyUI Workflow Test Outputs
============================================================

This script validates that images generated by ComfyUI workflows contain the expected
metadata based on the workflow configuration. It reads metadata from PNG, JPEG, and WebP
images and compares it against expected values derived from the workflow JSON files.

Usage
-----
    python validate_metadata.py --output-folder "path/to/output/Test" [options]

Options
-------
    --output-folder, -o     Path to folder containing generated images (required)
    --workflow-folder, -w   Path to folder containing workflow JSON files
    --comfyui-models-path   Path to ComfyUI models folder for hash sidecar validation
    --verbose, -v           Print detailed reverse validation info for each field
    --show-fields           Print all parsed metadata fields for each image

Requirements
------------
    - Pillow (PIL) for image handling
    - piexif (optional, for enhanced EXIF reading)

Architecture Overview
---------------------
The validation script consists of three main components:

1. **MetadataReader**: Reads metadata from various image formats
   - PNG: Reads from PNG text chunks (parameters field)
   - JPEG: Reads from EXIF UserComment field (with fallback modes)
   - WebP: Reads from EXIF data or XMP metadata

2. **WorkflowAnalyzer**: Parses workflow JSON files to extract expected metadata
   - Finds SaveImageWithMetaDataUniversal nodes
   - Resolves linked values (seeds, prompts, model names)
   - Traces model hierarchy (checkpoints, LoRAs, VAEs)
   - Extracts sampler/scheduler configurations

3. **MetadataValidator**: Compares actual metadata against expected values
   - Performs forward validation (expected → actual)
   - Performs reverse validation (actual fields → checked?)
   - Reports errors, warnings, and detailed check results

The "expected" metadata for forward validation is sourced from
`saveimage_unimeta/defs/meta.py` (what is actually registered to those metafields is
determined by the heuristics in `saveimage_unimeta/nodes/scanner.py`). Each test workflow
is parsed and traced to identify every metafield that *should*
appear in the saved image (seed, steps, prompts, model hierarchy, LoRA stack, hashes,
etc.). The validator then ensures that each of those expected fields is validated against
the actual metadata for the image produced by that workflow.


VALIDATION CHECKS
=================

The script performs two types of validation:

A) FORWARD VALIDATION (Expected → Actual)
-----------------------------------------
Validates that metadata contains expected values from the workflow. Every
metafield defined by the Save Image node (per `saveimage_unimeta/defs/meta.py`)
must be validated when the corresponding feature is present in the workflow (for
example: if the workflow loads three LoRAs the validator must assert that the
metadata also reports three LoRAs).

    PER-WORKFLOW MANDATORY CHECKS:
    - **LoRA count**: If the workflow loads any LoRAs, verify that the number of
        `Lora_N` entries in metadata equals the number of loras loaded in the
        workflow (loras can be loaded in single-model loaders, inline (only by a select few nodes), stack loaders, etc.) (1 check per
            workflow when applicable).
    - **Hash uniqueness**: Ensure every recorded artifact hash (model, VAE, each
        LoRA, each embedding) is unique (1 check per workflow).
    - **Metadata generator version**: Confirm the `Metadata generator version`
        field is present and non-empty (1 check per workflow).
    - **Self-validation of core fields**: Seed, Steps, Sampler, Model, Model
        hash, Denoise, and at least one of {CFG scale, Guidance} must each have a
        corresponding forward-validation check. Missing checks trigger reverse
        validation failures (≥5 checks per workflow).

  CORE SAMPLING FIELDS:
  - Seed: Validates seed value matches expected. For random seeds (-1),
          accepts any 13-18 digit numeric value.
  - Steps: Numeric comparison of step count.
  - CFG scale: Numeric comparison. Respects guidance_as_cfg toggle which
               uses Guidance value as CFG for Flux workflows.
  - Guidance: Numeric comparison (only if not using guidance_as_cfg).
  - Denoise: Numeric comparison of denoise strength.

  SAMPLER/SCHEDULER:
  - Sampler: Validates sampler name. Supports two modes:
      * Civitai mode: Converts internal names (euler_ancestral → "Euler a")
        with scheduler suffix handling (karras, exponential)
      * Non-Civitai mode: Uses raw sampler_name + scheduler combination

  MODEL/VAE FIELDS:
  - Model: Basename comparison (ignores path, compares stem only)
  - Model hash: Validates hash is present and not N/A
  - VAE: Basename comparison (skipped for "Baked VAE")
  - VAE hash: Validates hash is present (N/A allowed for Baked VAE)
  - Clip skip: Numeric comparison (absolute value)
  - Weight dtype: String comparison

  IMAGE DIMENSIONS:
  - Size: Format "{width}x{height}". Mismatch is a warning, not error.

  LORA STACK:
  - LoRA count: Validates expected number of LoRAs present
  - Per LoRA (Lora_N fields):
      * Model name: Basename comparison
            * Model hash: Must be present and not N/A
            * Strength model: Numeric comparison (Must be present and not N/A)
            * Strength clip: Numeric comparison (if specified; must not be N/A)

    PER-MODEL HASH AND FIELD CONSISTENCY:
    - **Hashes presence parity**: Every artifact recorded in the parameters
        string (model, LoRAs, VAE, embeddings) must also appear in the `Hashes`
        summary JSON (1 check per artifact).
    - **Hashes equality**: Each artifact’s metadata hash must equal its
        counterpart inside the `Hashes` JSON (1 check per artifact).
    - **Companion field coverage**: Related fields must exist together:
            * LoRA: model ↔ hash ↔ strength relationships (6 checks per LoRA: model
                has hash, model has strength, hash has model, hash has strength,
                strength has model, strength has hash).
            * VAE: `VAE` ↔ `VAE hash` (2 checks per VAE).
            * Model: `Model` ↔ `Model hash` (2 checks per model).
            * Embedding: `Embedding_N name` ↔ `Embedding_N hash` (2 checks per
                embedding).

  PROMPTS:
  - Positive prompt: String comparison (supports dual T5/CLIP prompts)
  - Negative prompt: String comparison
  - T5 Prompt: String comparison (Flux-specific)
  - CLIP Prompt: String comparison (Flux-specific)

  FLUX-SPECIFIC FIELDS:
  - Base shift: Numeric comparison
  - Max shift: Numeric comparison
  - Shift: Numeric comparison

  BATCH FIELDS:
  - Batch size: Numeric comparison (only validated if != 1)
  - Batch number: Numeric comparison

  EXTRA METADATA:
  - User-defined key-value pairs from CreateExtraMetaDataUniversal nodes
  - Recorded as "Extra: {key}" in check details

  HASH VALIDATION:
  - Validates Hashes JSON summary field matches individual hash entries
  - Cross-references hashes against .sha256 sidecar files (if models path provided)


B) REVERSE VALIDATION (Actual Fields → Checked?)
------------------------------------------------
Verifies every field found in metadata has a corresponding validation check.
This ensures the validator doesn't silently ignore any metadata fields. For each
metadata field (Positive prompt, Negative prompt, LoRA strengths, hash entries,
extra metadata keys, etc.) the script searches the forward-validation
`check_details` to confirm that specific field was tested for the given
workflow/image pair. Missing coverage is flagged as a reverse validation
failure, helping surface any gaps in the validation suite.

  CHECK SOURCES (how a field can pass reverse validation):

  1. "direct": Field name appears in check_details from forward validation
     - Most fields pass this way (Seed, Steps, Model, etc.)

  2. "extra_metadata": Field validated as "Extra: {field}" in check_details
     - Custom fields from CreateExtraMetaDataUniversal nodes

  3. "hashes_summary": Hashes field validated via Hashes-related checks
     - The JSON Hashes summary field

  4. "informational": Fields that don't need validation
     - "Metadata Fallback": Indicates fallback mode was used
     - "LoRAs": Summary display field (individual LoRAs validated separately)
     - "Samplers": Summary display field

  5. "always_validated": Fields implicitly validated
     - "Metadata generator version": Always present, format verified

    MISSING REQUIRED FIELD CHECKS:
    The reverse validation also tracks "missing required checks" - required
    core fields that are present in metadata but weren't validated. This acts as a
    self-test to ensure the validator keeps checking mandatory fields:
    - Seed, Steps, Sampler, Model, Model hash, Metadata generator version
    - CFG scale OR Guidance (at least one must be checked if present)
    - Denoise (should always be validated, as it is present in every test workflow)


C) STRUCTURAL VALIDATION
------------------------
Additional checks for metadata integrity:

  N/A VALUE DETECTION:
  - Flags any field containing literal "N/A" value
  - Exception: VAE hash with Baked VAE

  HASHES SUMMARY VALIDATION (_validate_hashes_summary):
  - Parses Hashes JSON field
  - Validates LoRA entries match Lora_N hash fields
  - Validates embedding entries match Embedding_N hash fields
  - Validates model/VAE entries match corresponding hash fields
  - Records check details for each hash comparison

  HASH SIDECAR VALIDATION (_validate_hashes_against_sidecars):
  - If comfyui_models_path provided, reads .sha256 sidecar files
  - Validates metadata hashes match full SHA256 (truncated to 10 chars)
  - Checks Model hash, VAE hash, LoRA hashes

  EMBEDDING FIELD VALIDATION (_validate_embedding_fields):
  - Checks embedding names don't have trailing punctuation
  - Flags suspiciously long embedding names (>100 chars, likely prompts)
  - Flags suspiciously long embedding hashes (>70 chars, likely prompts)

  REQUIRED FIELD PAIRS (_validate_required_field_pairs):
  - Model must have Model hash
  - VAE must have VAE hash (unless Baked VAE)
  - Each Lora_N must have: Model name, Model hash, Strength model
  - Each Embedding_N must have: name, hash

  HASH UNIQUENESS (_validate_hash_uniqueness):
  - Ensures all artifact hashes are unique
  - Checks: Model, VAE, all LoRAs, all Embeddings
  - Flags any duplicate hashes

  FILE FORMAT VALIDATION:
  - Validates image file extension matches expected format from save node


OUTPUT FORMAT
=============

The script produces a summary report with:

1. **Per-Image Results**: Pass/fail status with error counts

2. **Checks Per Image**: Number of validation checks per image
   Example: "workflow_00001_.png: 26 checks (25 passed, 1 failed)"

3. **Validation Summary**: Aggregate statistics
   - Total images validated
   - Images passed/failed
   - Total checks performed
   - Checks passed/failed/warnings

4. **Failed Images**: List of images that failed validation with error details

5. **Failed Reverse Validation Checks**: Images with fields not covered by forward validation
   Shows which metadata fields had no corresponding validation check

6. **Missing Required Field Checks**: Images where required fields weren't validated
   Lists per-image which required fields were present but not checked


EXIT CODES
==========
- 0: All validations passed
- 1: One or more validations failed


IMPLEMENTATION NOTES
====================

Sampler Name Resolution:
  The script mirrors the sampler name composition logic from capture.py.
  For Civitai-compatible names, it maps internal ComfyUI sampler names to
  their A1111/Civitai equivalents (e.g., "euler_ancestral" → "Euler a").

Model Name Comparison:
  Only the basename (stem) is compared, ignoring file paths. This allows
  workflows to reference models with full paths while metadata stores just
  the filename.

Seed Handling:
  Random seeds (indicated by -1 in workflow) generate platform-dependent
  values. The validator accepts any 13-18 digit numeric string for these.

Baked VAE Detection:
  VAEs are considered "baked" when the VAE field contains "Baked VAE" or
  the VAE hash is "N/A". Baked VAE images skip VAE hash validation.

Control Image Detection:
  Images with "without-meta" in the filename are treated as control images
  that should have no metadata. They pass validation if metadata is absent.
"""

import argparse
import atexit
import json
import logging
import math
import re
import sys
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)

TOOLS_DIR = Path(__file__).resolve().parent
TESTS_ROOT = TOOLS_DIR.parent
CLI_COMPAT_DIR = TESTS_ROOT / "comfyui_cli_tests"


def _resolve_relative_path(raw_path: str | None, *, fallback: Path | None = None) -> Path | None:
    """Resolve relative paths against tools/tests compatibility directories."""

    if raw_path is None:
        return None

    candidate = Path(raw_path).expanduser()
    if candidate.is_absolute():
        return candidate

    search_roots = []
    if fallback is not None:
        search_roots.append(fallback)
    search_roots.extend([TOOLS_DIR, TESTS_ROOT, CLI_COMPAT_DIR])

    for root in search_roots:
        resolved = (root / raw_path).resolve()
        if resolved.exists():
            return resolved

    base = fallback or TOOLS_DIR
    return (base / raw_path).resolve()


try:
    from PIL import Image
    from PIL.ExifTags import TAGS
except ImportError:
    print("Error: Pillow is required. Install with: pip install Pillow")
    sys.exit(1)

try:
    import piexif

    PIEXIF_AVAILABLE = True
except ImportError:
    PIEXIF_AVAILABLE = False


class _Tee:
    def __init__(self, stream, log_fp):
        self._stream = stream
        self._log_fp = log_fp

    def write(self, data):
        try:
            self._stream.write(data)
        except (ValueError, AttributeError):
            # Stream might be closed during shutdown
            pass
        try:
            if self._log_fp and not self._log_fp.closed:
                self._log_fp.write(data)
        except (ValueError, AttributeError):
            # Log file might be closed during shutdown
            pass

    def flush(self):
        try:
            self._stream.flush()
        except (ValueError, AttributeError):
            # Stream might be closed during shutdown, ignore flush errors
            pass
        try:
            if self._log_fp and not self._log_fp.closed:
                self._log_fp.flush()
        except (ValueError, AttributeError):
            # Log file might be closed during shutdown, ignore flush errors
            pass


def setup_print_tee(log_file: Path):
    # Ensure parent directory exists
    log_file.parent.mkdir(parents=True, exist_ok=True)
    # Open once; close at exit
    log_fp = open(log_file, "w", encoding="utf-8")

    # Safe close function that handles exceptions during shutdown
    def safe_close():
        try:
            if log_fp and not log_fp.closed:
                log_fp.flush()
                log_fp.close()
        except Exception:
            # Ignore exceptions during shutdown
            pass

    atexit.register(safe_close)

    # Tee both stdout and stderr to the same file
    sys.stdout = _Tee(sys.stdout, log_fp)
    sys.stderr = _Tee(sys.stderr, log_fp)


class MetadataReader:
    """Reads metadata from various image formats."""

    @staticmethod
    def _decode_text_value(raw_value: Any) -> str | None:
        """Return a UTF-8/UTF-16 decoded string for metadata chunks."""

        if isinstance(raw_value, str):
            text = raw_value.strip()
            return text if text else raw_value

        if isinstance(raw_value, bytes):
            has_nulls = b"\x00" in raw_value
            candidate_encodings: list[str] = []
            if has_nulls:
                candidate_encodings.extend(["utf-16", "utf-16le", "utf-16be"])
            candidate_encodings.extend(["utf-8", "latin-1"])

            seen_encodings: set[str] = set()
            for encoding in candidate_encodings:
                if encoding in seen_encodings:
                    continue
                seen_encodings.add(encoding)
                try:
                    decoded = raw_value.decode(encoding, errors="replace")
                except UnicodeDecodeError:
                    continue
                cleaned = decoded.replace("\x00", "").strip()
                if cleaned:
                    return cleaned

        try:
            text = str(raw_value)
            return text.strip() if text else None
        except Exception:
            return None

    @staticmethod
    def read_png_metadata(image_path: Path) -> dict[str, str]:
        """Read metadata from PNG file."""
        metadata = {}
        try:
            img = Image.open(image_path)

            # Try to get PNG info
            if hasattr(img, "info") and img.info:
                # Look for parameters in PNG metadata
                if "parameters" in img.info:
                    decoded = MetadataReader._decode_text_value(img.info["parameters"])
                    if decoded:
                        metadata["parameters"] = decoded

                # Copy all text chunks and normalize the parameters key casing
                for key, value in img.info.items():
                    decoded = MetadataReader._decode_text_value(value)
                    if not decoded:
                        continue
                    metadata[key] = decoded
                    if isinstance(key, str) and key.lower() == "parameters":
                        metadata["parameters"] = decoded

            # Alternative: read from binary if structured metadata not found
            if not metadata:
                with open(image_path, "rb") as f:
                    binary_content = f.read()
                    extracted = MetadataReader._extract_parameters_from_binary(binary_content)
                    if extracted:
                        metadata["parameters"] = extracted
        except Exception as e:
            print(f"  Warning: Error reading PNG metadata from {image_path.name}: {e}")

        return metadata

    @staticmethod
    def decode_user_comment(user_comment: bytes) -> str:
        """Decode EXIF UserComment field (handles ASCII/Unicode/JIS markers)."""

        if not isinstance(user_comment, bytes | bytearray):
            return str(user_comment)

        comment_bytes = bytes(user_comment)
        payload = comment_bytes
        encoding_hint: str | None = None

        if len(comment_bytes) >= 8:
            prefix = comment_bytes[:8]
            try:
                marker = prefix.rstrip(b"\x00").decode("ascii", errors="ignore").upper()
            except Exception:
                marker = ""

            if marker in {"ASCII", "UNICODE", "JIS"}:
                encoding_hint = marker
                payload = comment_bytes[8:]
            elif marker.startswith("UNICODE"):
                # Some encoders repeat the literal "UNICODE" without the EXIF padding.
                encoding_hint = "UNICODE"
                payload = comment_bytes[8:]

        def _try_decode(data: bytes, *encodings: str) -> str | None:
            for encoding in encodings:
                try:
                    decoded = data.decode(encoding, errors="backslashreplace").strip("\x00")
                except UnicodeDecodeError:
                    continue
                if decoded:
                    return decoded
            return None

        if encoding_hint == "ASCII":
            decoded = _try_decode(payload, "ascii", "utf-8")
            if decoded:
                return decoded

        if encoding_hint == "UNICODE":
            decoded = _try_decode(payload, "utf-16be", "utf-16le")
            if decoded:
                return decoded

        if encoding_hint == "JIS":
            decoded = _try_decode(payload, "shift_jis", "utf-8")
            if decoded:
                return decoded

        # Heuristic fallbacks: detect UTF-16 by null bytes, else attempt UTF-8/Latin-1
        has_nulls = b"\x00" in payload
        if has_nulls:
            decoded = _try_decode(payload, "utf-16be", "utf-16le")
            if decoded:
                return decoded

        decoded = _try_decode(payload, "utf-8", "latin-1")
        if decoded:
            return decoded

        decoded = MetadataReader._decode_text_value(payload)
        if decoded:
            return decoded

        return str(user_comment)

    @staticmethod
    def read_jpeg_metadata(image_path: Path) -> dict[str, str]:
        """Read metadata from JPEG file."""
        metadata = {}
        try:
            img = Image.open(image_path)

            # Try using piexif if available
            if PIEXIF_AVAILABLE:
                try:
                    exif_dict = piexif.load(str(image_path))
                    if piexif.ExifIFD.UserComment in exif_dict.get("Exif", {}):
                        user_comment = exif_dict["Exif"][piexif.ExifIFD.UserComment]
                        metadata["parameters"] = MetadataReader.decode_user_comment(user_comment)
                except Exception as e:
                    print(f"  Warning: piexif failed to read EXIF from {image_path.name}: {e}")

            # Fallback to PIL's EXIF reading
            if not metadata and hasattr(img, "_getexif") and img._getexif():
                exif_data = img._getexif()
                for tag, value in exif_data.items():
                    tag_name = TAGS.get(tag, tag)
                    if tag_name == "UserComment" and isinstance(value, bytes):
                        decoded = MetadataReader.decode_user_comment(value)
                        metadata["parameters"] = decoded
                        break

            # Check for JPEG comment marker (fallback mode)
            if not metadata:
                with open(image_path, "rb") as f:
                    content = f.read()
                    # Look for COM marker
                    # JPEG COM (comment) marker is represented by the byte sequence 0xFF 0xFE.
                    # This check detects if the image contains a comment marker, used for fallback metadata.
                    if b"\xff\xfe" in content:
                        metadata["_fallback_mode"] = "com-marker"
        except Exception as e:
            print(f"  Warning: Error reading JPEG metadata from {image_path.name}: {e}")

        return metadata

    @staticmethod
    def read_webp_metadata(image_path: Path) -> dict[str, str]:
        """Read metadata from WebP file."""
        metadata = {}
        try:
            img = Image.open(image_path)

            # WebP can have EXIF data
            if PIEXIF_AVAILABLE and "exif" in img.info:
                try:
                    exif_dict = piexif.load(img.info["exif"])
                    if piexif.ExifIFD.UserComment in exif_dict.get("Exif", {}):
                        user_comment = exif_dict["Exif"][piexif.ExifIFD.UserComment]
                        metadata["parameters"] = MetadataReader.decode_user_comment(user_comment)
                except Exception as exif_error:
                    print(f"  Warning: Error reading EXIF from WebP {image_path.name}: {exif_error}")

            # PIL>=10 exposes getexif for WebP; use it when piexif path fails
            if "parameters" not in metadata:
                pil_getexif = getattr(img, "getexif", None)
                pil_exif = None
                if callable(pil_getexif):
                    try:
                        pil_exif = pil_getexif()
                    except Exception:
                        pil_exif = None
                if not pil_exif:
                    pil_exif = getattr(img, "_getexif", lambda: None)()

                if pil_exif:
                    user_comment = pil_exif.get(0x9286)
                    if isinstance(user_comment, bytes):
                        decoded = MetadataReader.decode_user_comment(user_comment)
                        if decoded:
                            metadata["parameters"] = decoded

            # Check other WebP metadata
            if hasattr(img, "info"):
                for key, value in img.info.items():
                    decoded = MetadataReader._decode_text_value(value)
                    if not decoded:
                        continue
                    metadata[key] = decoded
                    if isinstance(key, str) and key.lower() == "parameters":
                        metadata["parameters"] = decoded

            # As a last resort, scan the raw file for ASCII 'parameters' blocks
            if "parameters" not in metadata:
                with open(image_path, "rb") as f:
                    binary_content = f.read()
                extracted = MetadataReader._extract_parameters_from_binary(binary_content)
                if extracted:
                    metadata["parameters"] = extracted
        except Exception as e:
            print(f"  Warning: Error reading WebP metadata from {image_path.name}: {e}")

        return metadata

    @staticmethod
    def _extract_parameters_from_binary(binary_content: bytes) -> str | None:
        """Attempt to recover the metadata text block directly from binary bytes."""

        if not binary_content:
            return None

        def _looks_like_parameters(text: str) -> bool:
            tokens = ("Steps:", "Sampler:", "Metadata generator version")
            return any(token in text for token in tokens)

        def _clean_text(raw: str) -> str:
            return raw.replace("\x00", "").strip()

        def _decode_chunk(chunk: bytes, encodings: tuple[str, ...]) -> str | None:
            for encoding in encodings:
                try:
                    decoded = chunk.decode(encoding, errors="ignore")
                except Exception:
                    continue
                cleaned = _clean_text(decoded)
                if _looks_like_parameters(cleaned):
                    return cleaned
            return None

        ascii_idx = binary_content.find(b"parameters")
        if ascii_idx != -1:
            chunk = binary_content[ascii_idx : ascii_idx + 65536]
            decoded = _decode_chunk(chunk, ("utf-8", "latin-1"))
            if decoded:
                return decoded

        for encoding in ("utf-16be", "utf-16le"):
            marker = "parameters".encode(encoding)
            idx = binary_content.find(marker)
            if idx != -1:
                chunk = binary_content[idx : idx + 65536]
                decoded = _decode_chunk(chunk, (encoding, "utf-16"))
                if decoded:
                    return decoded

        unicode_idx = binary_content.find(b"UNICODE")
        if unicode_idx != -1:
            chunk = binary_content[unicode_idx : unicode_idx + 65536]
            decoded = MetadataReader.decode_user_comment(chunk)
            cleaned = _clean_text(decoded)
            if _looks_like_parameters(cleaned):
                return cleaned

        return None

    @staticmethod
    def read_metadata(image_path: Path) -> dict[str, str]:
        """Read metadata from any supported image format."""
        ext = image_path.suffix.lower()

        if ext == ".png":
            return MetadataReader.read_png_metadata(image_path)
        elif ext in [".jpg", ".jpeg"]:
            return MetadataReader.read_jpeg_metadata(image_path)
        elif ext == ".webp":
            return MetadataReader.read_webp_metadata(image_path)
        else:
            print(f"  Warning: Unsupported image format: {ext}")
            return {}


class WorkflowAnalyzer:
    """Analyzes workflow JSON files to extract expected metadata."""

    @staticmethod
    def find_save_nodes(workflow: dict) -> list[tuple[str, dict]]:
        """Find all SaveImageWithMetaDataUniversal nodes in the workflow."""
        save_nodes = []
        for node_id, node_data in workflow.items():
            if node_data.get("class_type") == "SaveImageWithMetaDataUniversal":
                save_nodes.append((node_id, node_data))
        return save_nodes

    @staticmethod
    def find_save_node(workflow: dict) -> tuple[str | None, dict | None]:
        """Find the first Save Image node in the workflow (for backward compatibility)."""
        nodes = WorkflowAnalyzer.find_save_nodes(workflow)
        return nodes[0] if nodes else (None, None)

    @staticmethod
    def find_sampler_nodes(workflow: dict) -> list[tuple[str, dict]]:
        """Find all sampler-like nodes in the workflow."""
        samplers = []
        for node_id, node_data in workflow.items():
            if WorkflowAnalyzer._is_sampler_node(node_data.get("class_type"), node_data.get("inputs")):
                samplers.append((node_id, node_data))
        return samplers

    @staticmethod
    def _is_sampler_node(class_type: str | None, inputs: dict | None = None) -> bool:
        """Return True when the node represents an actual sampler invocation."""

        if not class_type:
            return False

        lower_class = class_type.lower()
        if "sampler" not in lower_class:
            return False

        # Exclude selector/helper/configuration nodes that should not be treated as samplers
        excluded_tokens = ("select", "helper", "scheduler", "writer")
        if any(token in lower_class for token in excluded_tokens):
            return False

        if inputs:
            has_core_input = any(key in inputs for key in ("latent", "latent_image", "model", "guider", "sigmas"))
            has_step_or_cfg = inputs.get("steps") is not None or inputs.get("cfg") is not None
            if not has_core_input and not has_step_or_cfg:
                return False

        return True

    @staticmethod
    def resolve_filename_prefix(workflow: dict, filename_prefix: Any) -> str:
        """Resolve filename_prefix which may be a string or a link to another node.

        Args:
            workflow: Dictionary with string keys representing node IDs
            filename_prefix: Either a string or a list [node_id, output_index] linking to another node

        Returns:
            The resolved filename prefix string. Returns empty string if:
            - filename_prefix is a list but the linked node doesn't exist
            - The linked node has no 'value' in its inputs
            - filename_prefix is neither a string nor a list
        """
        if isinstance(filename_prefix, list):
            # It's a link to another node [node_id, output_index]
            link_node_id = str(filename_prefix[0])
            if link_node_id in workflow:
                linked_node = workflow[link_node_id]
                # Get the value from the linked node's inputs
                return linked_node.get("inputs", {}).get("value", "")
        return filename_prefix if isinstance(filename_prefix, str) else ""

    @staticmethod
    def resolve_seed_value(workflow: dict, seed_input: Any) -> str | None:
        """Resolve the expected seed value, including linked seed nodes."""

        if seed_input is None:
            return None

        # Direct literal value
        if not isinstance(seed_input, list):
            if seed_input in (-1, "-1"):
                return "-1"
            return str(seed_input)

        if not seed_input:
            return None

        seed_node_id = str(seed_input[0])
        seed_node = workflow.get(seed_node_id)
        if not seed_node:
            return None

        node_inputs = seed_node.get("inputs", {})

        for key in ("seed", "noise_seed", "value"):
            if key in node_inputs:
                value = node_inputs[key]
                # If the value is another link, we cannot resolve it deterministically
                if isinstance(value, list):
                    return None
                if value in (-1, "-1"):
                    return "-1"
                return str(value)

        # Some seed nodes store the value under "seed_value"
        value = node_inputs.get("seed_value")
        if value is not None:
            if value in (-1, "-1"):
                return "-1"
            return str(value)

        return None

    @staticmethod
    def resolve_guidance_value(workflow: dict, sampler_inputs: dict) -> Any:
        """Resolve guidance (Flux guidance multiplier or CFG equivalent)."""

        direct_guidance = sampler_inputs.get("guidance")
        if direct_guidance is not None:
            return direct_guidance

        stack: list[str] = []
        visited: set[str] = set()

        positive_ref = sampler_inputs.get("positive")
        if isinstance(positive_ref, list) and positive_ref:
            stack.append(str(positive_ref[0]))

        guider_ref = sampler_inputs.get("guider")
        if isinstance(guider_ref, list) and guider_ref:
            stack.append(str(guider_ref[0]))

        while stack:
            node_id = stack.pop()
            if node_id in visited:
                continue
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                continue

            inputs = node.get("inputs", {})
            if inputs.get("guidance") is not None:
                return inputs.get("guidance")

            for key in ("conditioning", "positive", "clip", "input", "guider"):
                ref = inputs.get(key)
                if isinstance(ref, list) and ref:
                    stack.append(str(ref[0]))

        return None

    @staticmethod
    def resolve_text_input(workflow: dict, value: Any, visited: set[str] | None = None) -> str | None:
        """Resolve text-like inputs that may reference other nodes."""

        if value in (None, ""):
            return None

        if isinstance(value, str):
            return value

        if not isinstance(value, list) or not value:
            return None

        node_id = str(value[0])
        if visited is None:
            # Track visited nodes to prevent cycles
            visited = set()
        if node_id in visited:
            return None
        visited.add(node_id)

        node = workflow.get(node_id)
        if not node:
            return None

        node_inputs = node.get("inputs", {})
        class_type = node.get("class_type", "")

        # Handle ShowAny|unimeta nodes - they store displayed values in text_0, text_1, etc.
        if "ShowAny" in class_type:
            for key in ("text_0", "text_1", "text_2", "text_3"):
                text_val = node_inputs.get(key)
                if isinstance(text_val, str) and text_val:
                    return text_val

        # Direct text-bearing keys
        for key in (
            "value",
            "text",
            "string",
            "clip_l",
            "clip_g",
            "prompt",
            "t5xxl",
            "clip_prompt",
        ):
            direct_value = node_inputs.get(key)
            if isinstance(direct_value, str):
                return direct_value

        # Handle CLIPTextEncodeFlux list values specifically
        # The direct key loop above handles string values for t5xxl/clip_l.
        # This block handles list values (e.g., [node_ref, ...]) that the direct loop skips.
        if class_type == "CLIPTextEncodeFlux":
            for flux_key in ("t5xxl", "clip_l"):
                if flux_key not in node_inputs:
                    continue
                val = node_inputs[flux_key]
                if isinstance(val, list) and val:
                    flux_text = WorkflowAnalyzer.resolve_text_input(workflow, val, visited)
                    if flux_text:
                        return flux_text
                elif isinstance(val, str):
                    return val

        # Handle ConditioningCombine specifically to join multiple prompts
        if class_type == "ConditioningCombine":
            texts = []
            for key in ("conditioning_1", "conditioning_2"):
                linked = node_inputs.get(key)
                if isinstance(linked, list) and linked:
                    # Pass the original visited set to both branches to ensure that:
                    # 1. Shared ancestor nodes are tracked globally and not traversed twice
                    # 2. Cycles through ConditioningCombine nodes are properly detected
                    branch_text = WorkflowAnalyzer.resolve_text_input(workflow, linked, visited)
                    if branch_text:
                        texts.append(branch_text)

            if texts:
                # Join with a separator if multiple texts found
                return " ".join(texts)

        # Follow common linkage keys recursively
        # For generic nodes, we just take the first valid text we find
        for key in ("text", "value", "input", "conditioning", "guider", "clip"):
            linked = node_inputs.get(key)
            if isinstance(linked, list) and linked:
                resolved = WorkflowAnalyzer.resolve_text_input(workflow, linked, visited)
                if resolved:
                    return resolved

        return None

    @staticmethod
    def _resolve_strength_pair(
        inputs: dict,
        *,
        model_default: float = 1.0,
        clip_default: float = 1.0,
    ) -> tuple[float, float]:
        """Normalize LoRA strength fields across loader variants."""

        model_keys = [
            "strength_model",
            "model_strength",
            "lora_model_strength",
            "strength",
            "lora_wt",
        ]
        clip_keys = [
            "strength_clip",
            "clip_strength",
            "lora_clip_strength",
            "strength",
            "lora_wt",
        ]

        def _find_strength(keys: list[str], default: float, inputs: dict) -> float:
            """Find strength value, preferring specific keys over generic 'strength'/'lora_wt'."""
            # Check specific keys first (excluding generic ones)
            for key in keys:
                if key in inputs and inputs[key] not in (None, ""):
                    if key not in ("strength", "lora_wt"):
                        return inputs[key]
            # Fall back to generic keys
            for key in ("strength", "lora_wt"):
                if key in inputs and inputs[key] not in (None, ""):
                    return inputs[key]
            return default

        model_strength = _find_strength(model_keys, model_default, inputs)
        clip_strength = _find_strength(clip_keys, clip_default, inputs)

        return model_strength, clip_strength

    @staticmethod
    def _resolve_noise_seed(workflow: dict, noise_ref: Any) -> str | None:
        """Resolve seed from upstream noise nodes."""

        if not (isinstance(noise_ref, list) and noise_ref):
            return None

        node_id = str(noise_ref[0])
        node = workflow.get(node_id)
        if not node:
            return None

        inputs = node.get("inputs", {})
        for key in ("seed", "noise_seed", "value"):
            if inputs.get(key) not in (None, ""):
                value = inputs[key]
                if isinstance(value, list):
                    return None
                return str(value)

        return None

    @staticmethod
    def _resolve_sampler_choice(workflow: dict, sampler_ref: Any) -> str | None:
        """Resolve sampler name from selection nodes like KSamplerSelect."""

        if not (isinstance(sampler_ref, list) and sampler_ref):
            return None

        node = workflow.get(str(sampler_ref[0]))
        if not node:
            return None

        inputs = node.get("inputs", {})
        for key in ("sampler_name", "sampler", "name"):
            value = inputs.get(key)
            if isinstance(value, str) and value:
                return value

        return None

    @staticmethod
    def _normalize_numeric(value: Any) -> int | None:
        """Convert numeric-like values (strings, floats) to ints when possible."""

        if value in (None, "", "None"):
            return None
        if isinstance(value, bool):
            return int(value)
        if isinstance(value, int | float):
            if isinstance(value, float):
                if not math.isfinite(value):
                    return None
                return int(round(value))
            return int(value)
        if isinstance(value, str):
            cleaned = value.strip()
            if not cleaned:
                return None
            match = re.search(r"-?\d+(?:\.\d+)?", cleaned)
            if not match:
                return None
            token = match.group(0)
            try:
                number = float(token)
            except ValueError:
                return None
            if not math.isfinite(number):
                return None
            return int(round(number))
        return None

    @staticmethod
    def _parse_dimension_value(value: Any) -> tuple[int | None, int | None]:
        """Extract (width, height) from strings, tuples, or dict-like payloads."""

        if isinstance(value, list | tuple):
            if len(value) >= 2:
                return (
                    WorkflowAnalyzer._normalize_numeric(value[0]),
                    WorkflowAnalyzer._normalize_numeric(value[1]),
                )
            return (None, None)

        if isinstance(value, dict):
            width = WorkflowAnalyzer._normalize_numeric(
                value.get("width") or value.get("w") or value.get("latent_width")
            )
            height = WorkflowAnalyzer._normalize_numeric(
                value.get("height") or value.get("h") or value.get("latent_height")
            )
            return width, height

        if isinstance(value, str):
            width = height = None
            if "x" in value.lower():
                parts = re.split(r"[xX]\s*", value)
                if len(parts) >= 2:
                    width = WorkflowAnalyzer._normalize_numeric(parts[0])
                    height = WorkflowAnalyzer._normalize_numeric(parts[1])
            if width is None or height is None:
                digits = re.findall(r"\d+", value)
                if len(digits) >= 2:
                    width = width or WorkflowAnalyzer._normalize_numeric(digits[0])
                    height = height or WorkflowAnalyzer._normalize_numeric(digits[1])
            return width, height

        return (None, None)

    @classmethod
    def _extract_latent_dimensions(cls, class_type: str, inputs: dict[str, Any]) -> dict[str, Any]:
        """Best-effort extraction of latent width/height/batch metadata."""

        width = None
        height = None
        batch_size = None

        width_keys = (
            "width",
            "latent_width",
            "empty_latent_width",
            "image_width",
            "output_width",
            "target_width",
        )
        height_keys = (
            "height",
            "latent_height",
            "empty_latent_height",
            "image_height",
            "output_height",
            "target_height",
        )
        batch_keys = ("batch_size", "batch_count", "count")

        for key in width_keys:
            if width is None and inputs.get(key) not in (None, ""):
                width = cls._normalize_numeric(inputs[key])

        for key in height_keys:
            if height is None and inputs.get(key) not in (None, ""):
                height = cls._normalize_numeric(inputs[key])

        for key in batch_keys:
            if batch_size is None and inputs.get(key) not in (None, ""):
                batch_size = cls._normalize_numeric(inputs[key])

        for key in ("dimensions", "dimension", "resolution", "size"):
            if width is not None and height is not None:
                break
            compound = inputs.get(key)
            parsed_width, parsed_height = cls._parse_dimension_value(compound)
            if width is None and parsed_width is not None:
                width = parsed_width
            if height is None and parsed_height is not None:
                height = parsed_height

        result: dict[str, Any] = {}
        if width is not None:
            result["image_width"] = width
        if height is not None:
            result["image_height"] = height
        if batch_size is not None:
            result["batch_size"] = batch_size

        return result

    @staticmethod
    def _looks_like_lora_stack_node(class_type: str, inputs: dict[str, Any]) -> bool:
        lower_class = class_type.lower()
        if "lorastack" in lower_class or "lora stack" in lower_class:
            return True
        for key in inputs.keys():
            if isinstance(key, str) and key.startswith("lora_name_"):
                return True
        return False

    @staticmethod
    def _add_lora_entry(collection: list[dict[str, Any]], name: Any, model_strength: Any, clip_strength: Any) -> None:
        if name in (None, "", "None"):
            return
        normalized_name = str(name)
        if not normalized_name:
            return
        existing = next((entry for entry in collection if entry.get("name") == normalized_name), None)
        if existing:
            if existing.get("model_strength") is None and model_strength is not None:
                existing["model_strength"] = model_strength
            if existing.get("clip_strength") is None and clip_strength is not None:
                existing["clip_strength"] = clip_strength
            return
        entry: dict[str, Any] = {
            "name": normalized_name,
            "model_strength": model_strength,
            "clip_strength": clip_strength,
        }
        collection.append(entry)

    @staticmethod
    def _dedupe_lora_entries(entries: list[dict[str, Any]]) -> list[dict[str, Any]]:
        seen: dict[str, dict[str, Any]] = {}
        for entry in entries:
            name = entry.get("name")
            if not name:
                continue
            if name not in seen:
                seen[name] = entry.copy()
                continue
            existing = seen[name]
            for key in ("model_strength", "clip_strength"):
                if existing.get(key) is None and entry.get(key) is not None:
                    existing[key] = entry[key]
        return list(seen.values())

    @staticmethod
    def _resolve_scheduler_metadata(workflow: dict, scheduler_ref: Any) -> dict[str, Any]:
        """Extract step/scheduler details from scheduler helper nodes."""

        metadata: dict[str, Any] = {}
        if not (isinstance(scheduler_ref, list) and scheduler_ref):
            return metadata

        stack = [str(scheduler_ref[0])]
        visited: set[str] = set()

        while stack:
            node_id = stack.pop()
            if node_id in visited:
                continue
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                continue

            inputs = node.get("inputs", {})
            for field in ("steps", "scheduler", "denoise"):
                if field not in metadata and inputs.get(field) not in (None, ""):
                    metadata[field] = inputs[field]

            # Some schedulers reference additional nodes via "model"; follow chain once
            for key in ("model", "scheduler", "sigmas"):
                ref = inputs.get(key)
                if isinstance(ref, list) and ref:
                    stack.append(str(ref[0]))

        return metadata

    @staticmethod
    def resolve_model_hierarchy(workflow: dict, sampler_id: str) -> dict[str, Any]:
        """Trace the sampler's model chain to find checkpoint, LoRAs, and related settings."""

        info: dict[str, Any] = {
            "model_name": None,
            "clip_model_name": None,
            "clip_skip": None,
            "weight_dtype": None,
            "lora_stack": [],
            "vae_name": None,
        }

        sampler_node = workflow.get(sampler_id)
        if not sampler_node:
            return info

        queue: list[str] = []
        visited: set[str] = set()

        def enqueue(ref: Any):
            if isinstance(ref, list) and ref:
                node_id = str(ref[0])
                if node_id not in visited:
                    queue.append(node_id)

        for key in ("model", "guider", "sampler", "sigmas", "input", "lora_stack"):
            enqueue(sampler_node.get("inputs", {}).get(key))

        while queue:
            node_id = queue.pop(0)
            if node_id in visited:
                continue
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                continue

            class_type = node.get("class_type", "")
            inputs = node.get("inputs", {})
            lower_class = class_type.lower()

            if "lora" in lower_class and inputs.get("lora_name") not in (None, "", "None"):
                model_strength, clip_strength = WorkflowAnalyzer._resolve_strength_pair(inputs)
                normalized_class = lower_class.replace("_", "").replace(" ", "")
                if "modelonly" in normalized_class:
                    clip_strength = None
                WorkflowAnalyzer._add_lora_entry(
                    info.setdefault("lora_stack", []),
                    inputs.get("lora_name") or inputs.get("name"),
                    model_strength,
                    clip_strength,
                )

                enqueue(inputs.get("model"))
                enqueue(inputs.get("unet"))
                enqueue(inputs.get("clip"))
                continue

            if WorkflowAnalyzer._looks_like_lora_stack_node(class_type, inputs):
                stack_entries = WorkflowAnalyzer.extract_lora_stack_info(workflow, node_id)
                for entry in stack_entries:
                    WorkflowAnalyzer._add_lora_entry(
                        info.setdefault("lora_stack", []),
                        entry.get("name"),
                        entry.get("model_strength"),
                        entry.get("clip_strength"),
                    )

            checkpoint_keywords = (
                "checkpointloader",
                "model loader",
                "unetloader",
                "fluxunetloader",
                "checkpoint",
            )

            normalized_class = re.sub(r"[\s._-]+", "", lower_class)
            is_efficient_loader = "efficientloader" in normalized_class or normalized_class.startswith("effloader")

            if any(keyword in lower_class for keyword in checkpoint_keywords) or is_efficient_loader:
                model_candidate = (
                    inputs.get("ckpt_name")
                    or inputs.get("checkpoint_name")
                    or inputs.get("model_name")
                    or inputs.get("unet_name")
                    or inputs.get("base_ckpt_name")
                )
                if model_candidate and not info.get("model_name"):
                    info["model_name"] = model_candidate

                clip_candidate = inputs.get("clip_name") or inputs.get("clip_l_name") or inputs.get("clip_g_name")
                clip_candidate = clip_candidate or inputs.get("clip_name1") or inputs.get("clip")
                if clip_candidate and not info.get("clip_model_name"):
                    info["clip_model_name"] = clip_candidate

                clip_skip_value = inputs.get("clip_skip", inputs.get("base_clip_skip"))
                if clip_skip_value is not None and info.get("clip_skip") is None:
                    info["clip_skip"] = clip_skip_value

                weight_dtype = inputs.get("weight_dtype") or inputs.get("dtype")
                if weight_dtype and not info.get("weight_dtype"):
                    info["weight_dtype"] = weight_dtype

                vae_candidate = inputs.get("vae_name") or inputs.get("vae_file") or inputs.get("clip_vae")
                vae_candidate = vae_candidate or inputs.get("optional_vae")
                if vae_candidate and not info.get("vae_name"):
                    info["vae_name"] = vae_candidate
                continue

            if class_type in {"ModelSamplingFlux", "ModelSamplingSD3"}:
                info["base_shift"] = inputs.get("base_shift")
                info["max_shift"] = inputs.get("max_shift")
                enqueue(inputs.get("model"))
                enqueue(inputs.get("unet"))
                enqueue(inputs.get("input"))
                enqueue(inputs.get("base_model"))
                continue

            if "cliploader" in lower_class or "dualclip" in lower_class:
                if not info.get("clip_model_name"):
                    info["clip_model_name"] = inputs.get("clip_name") or inputs.get("clip_name1") or inputs.get("clip")

            for key in ("model", "unet", "input", "base_model", "lora_stack"):
                enqueue(inputs.get(key))

            if class_type in {"VAELoader", "VAELoaderSimple", "FluxVAELoader"} and not info.get("vae_name"):
                vae_candidate = inputs.get("vae_name") or inputs.get("clip_vae") or inputs.get("vae_file")
                if vae_candidate:
                    info["vae_name"] = vae_candidate

        return info

    @staticmethod
    def resolve_vae_name(workflow: dict, save_node_id: str) -> str | None:
        """Trace from the save node to find the associated VAE loader name."""

        save_node = workflow.get(save_node_id)
        if not save_node:
            return None

        images_ref = save_node.get("inputs", {}).get("images")
        if not (isinstance(images_ref, list) and images_ref):
            return None

        stack = [str(images_ref[0])]
        visited: set[str] = set()

        while stack:
            node_id = stack.pop()
            if node_id in visited:
                continue
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                continue

            class_type = node.get("class_type", "")
            inputs = node.get("inputs", {})

            if class_type in {"VAELoader", "VAELoaderSimple", "FluxVAELoader"}:
                return inputs.get("vae_name") or inputs.get("clip_vae") or inputs.get("vae_file") or inputs.get("ckpt_name")

            lower_class = class_type.lower()
            if "efficient loader" in lower_class and inputs.get("vae_name"):
                return inputs.get("vae_name")

            if "vae" in class_type.lower():
                vae_ref = inputs.get("vae")
                if isinstance(vae_ref, list) and vae_ref:
                    stack.append(str(vae_ref[0]))

            for key in ("samples", "latent_image", "images", "input", "optional_vae"):
                ref = inputs.get(key)
                if isinstance(ref, list) and ref:
                    stack.append(str(ref[0]))

        return None

    @staticmethod
    def resolve_latent_attributes(workflow: dict, sampler_inputs: dict) -> dict[str, Any]:
        """Derive width, height, batch size by tracing latent sources feeding the sampler."""

        latent_refs: list[str] = []
        for key in ("latent_image", "latent", "samples", "input", "images"):
            ref = sampler_inputs.get(key)
            if isinstance(ref, list) and ref:
                latent_refs.append(str(ref[0]))

        if not latent_refs:
            return {}

        stack = latent_refs[:]
        visited: set[str] = set()
        resolved: dict[str, Any] = {"image_width": None, "image_height": None, "batch_size": None}

        while stack:
            node_id = stack.pop()
            if node_id in visited:
                continue
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                continue

            class_type = node.get("class_type", "")
            inputs = node.get("inputs", {})

            dims = WorkflowAnalyzer._extract_latent_dimensions(class_type, inputs)
            for key, value in dims.items():
                if value is not None and resolved.get(key) is None:
                    resolved[key] = value

            if (
                resolved.get("image_width") is not None
                and resolved.get("image_height") is not None
                and resolved.get("batch_size") is not None
            ):
                break

            for key in (
                "samples",
                "latent_image",
                "input",
                "latent",
                "images",
                "clip_latent",
                "base_latent",
            ):
                ref = inputs.get(key)
                if isinstance(ref, list) and ref:
                    stack.append(str(ref[0]))

        return {key: value for key, value in resolved.items() if value is not None}

    @staticmethod
    def extract_filename_patterns(workflow: dict) -> list[str]:
        """Extract filename prefix tokens from save nodes for workflow detection.

        Returns a list of simplified patterns that can be used for matching.
        For example, "Test\\flux-CR-LoRA-stack" becomes "flux-CR-LoRA-stack".
        For complex paths like "Test\\siwm-%model:10%/%pprompt:20%", extracts "siwm".
        """
        patterns = []
        seen_patterns = set()  # Track unique patterns

        # Find SaveImageWithMetaDataUniversal nodes
        save_nodes = WorkflowAnalyzer.find_save_nodes(workflow)

        # Also find regular SaveImage nodes (for control images)
        for node_id, node_data in workflow.items():
            if node_data.get("class_type") == "SaveImage":
                save_nodes.append((node_id, node_data))

        for _, save_node in save_nodes:
            inputs = save_node.get("inputs", {})
            prefix = inputs.get("filename_prefix", "")

            # Resolve linked filename_prefix
            prefix = WorkflowAnalyzer.resolve_filename_prefix(workflow, prefix)

            if prefix:
                tokens = WorkflowAnalyzer._extract_prefix_tokens(prefix)
                for cleaned in tokens:
                    cleaned_lower = cleaned.lower()
                    if cleaned and len(cleaned) >= 3 and cleaned_lower not in {"test", "tests"} and cleaned_lower not in seen_patterns:
                        patterns.append(cleaned)
                        seen_patterns.add(cleaned_lower)

        return patterns

    @staticmethod
    def _clean_prefix_component(part: str) -> str:
        """Strip tokens/separators from a single filename_prefix component."""

        if not isinstance(part, str):
            return ""
        clean_part = part.strip()
        if not clean_part:
            return ""
        if clean_part.startswith("%") and clean_part.endswith("%"):
            return ""
        cleaned = re.sub(r"%[^%]+%", "", clean_part)
        cleaned = re.sub(r"^[x_\-/]+", "", cleaned)
        cleaned = re.sub(r"[x_\-/]+$", "", cleaned)
        cleaned = re.sub(r"_+", "_", cleaned)
        cleaned = re.sub(r"-+", "-", cleaned)
        return cleaned.strip("_-")

    @classmethod
    def _extract_prefix_tokens(cls, prefix: str) -> list[str]:
        if not prefix:
            return []
        tokens: list[str] = []
        parts = str(prefix).replace("\\", "/").split("/")
        for part in parts:
            cleaned = cls._clean_prefix_component(part)
            if cleaned:
                tokens.append(cleaned)
        return tokens

    @staticmethod
    def trace_node_input(workflow: dict, node_id: str, input_key: str) -> tuple[str | None, dict | None]:
        """Trace back through a node input connection to find the source node.

        Returns: (source_node_id, source_node) or (None, None) if not found
        """
        if node_id not in workflow:
            return None, None

        node = workflow[node_id]
        inputs = node.get("inputs", {})

        if input_key not in inputs:
            return None, None

        value = inputs[input_key]
        # If it's a list, it's a connection [node_id, output_index]
        if isinstance(value, list) and len(value) >= 1:
            source_id = str(value[0])
            if source_id in workflow:
                return source_id, workflow[source_id]

        return None, None

    @staticmethod
    def extract_lora_stack_info(workflow: dict, lora_stack_id: str) -> list[dict]:
        """Extract LoRA information from a LoRA Stacker node.

        Returns: List of dicts with {name, model_strength, clip_strength}
        """
        if lora_stack_id not in workflow:
            return []

        lora_stack_node = workflow[lora_stack_id]
        stack_inputs = lora_stack_node.get("inputs", {})

        mode = stack_inputs.get("input_mode", "simple")
        count = int(stack_inputs.get("lora_count", 0))

        loras = []
        for i in range(1, count + 1):
            name_key = f"lora_name_{i}"
            lora_name = stack_inputs.get(name_key)

            if lora_name and lora_name != "None":
                if mode == "advanced":
                    model_str = stack_inputs.get(f"model_str_{i}", 1.0)
                    clip_str = stack_inputs.get(f"clip_str_{i}", 1.0)
                else:
                    lora_wt = stack_inputs.get(f"lora_wt_{i}", 1.0)
                    model_str = lora_wt
                    clip_str = lora_wt

                loras.append({"name": lora_name, "model_strength": model_str, "clip_strength": clip_str})

        return loras

    @staticmethod
    def find_selected_sampler(
        workflow: dict,
        selection_method: str,
        selection_node_id: str | None,
    ) -> tuple[str | None, dict | None]:
        """Return the sampler node selected by the configured method."""
        # Find all KSampler nodes
        samplers = []
        for node_id, node_data in workflow.items():
            class_type = node_data.get("class_type", "")
            if "KSampler" in class_type or "SamplerCustom" in class_type:
                steps = node_data.get("inputs", {}).get("steps")
                if steps is not None:
                    samplers.append((node_id, node_data, int(steps)))

        if not samplers:
            return None, None

        if selection_method == "By node ID" and selection_node_id:
            # Find specific node
            for node_id, node_data, _ in samplers:
                if node_id == str(selection_node_id):
                    return node_id, node_data
            return None, None

        elif selection_method == "Farthest":
            # Find sampler with highest steps
            sampler_id, sampler_node, _ = max(samplers, key=lambda x: x[2])
            return sampler_id, sampler_node

        elif selection_method == "Nearest":
            # Find sampler with lowest steps
            sampler_id, sampler_node, _ = min(samplers, key=lambda x: x[2])
            return sampler_id, sampler_node

        # Default: return first sampler found
        return samplers[0][0], samplers[0][1]

    @staticmethod
    def get_connected_sampler_chain(workflow: dict, start_node_id: str) -> list[tuple[str, dict, int]]:
        """Trace back from a node to find all connected KSampler nodes in the lineage.

        Returns a list of (node_id, node_data, distance) tuples for all samplers found in the connected chain.
        The distance reflects how many hops the sampler sits upstream from the save node input, matching the
        "farthest/nearest" semantics used by the runtime node.
        """
        connected_samplers: list[tuple[str, dict, int]] = []
        visited: set[str] = set()
        queue: list[tuple[str, int]] = [(start_node_id, 0)]

        while queue:
            node_id, distance = queue.pop(0)
            if node_id in visited:
                continue
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                continue

            class_type = node.get("class_type", "")
            if WorkflowAnalyzer._is_sampler_node(class_type, node.get("inputs")):
                # Found a sampler in the chain
                connected_samplers.append((node_id, node, distance))

            # Trace inputs upstream
            inputs = node.get("inputs", {})
            for key, value in inputs.items():
                if isinstance(value, list) and len(value) >= 1:
                    source_id = str(value[0])
                    if source_id not in visited:
                        queue.append((source_id, distance + 1))

        return connected_samplers

    @staticmethod
    def resolve_extra_metadata(workflow: dict, extra_metadata_ref: Any) -> dict[str, str]:
        """Resolve extra metadata from CreateExtraMetaData nodes."""
        if not (isinstance(extra_metadata_ref, list) and extra_metadata_ref):
            return {}

        def _normalize_key(raw_key: Any) -> str:
            if raw_key in (None, ""):
                return ""
            value = raw_key
            if isinstance(value, list) and value:
                resolved = WorkflowAnalyzer.resolve_text_input(workflow, value)
                if resolved is not None:
                    value = resolved
                else:
                    value = value[0]
            try:
                return str(value)
            except Exception:
                return ""

        def _normalize_value(raw_value: Any) -> str | None:
            if raw_value in (None, ""):
                return None
            value = raw_value
            if isinstance(value, list) and value:
                resolved = WorkflowAnalyzer.resolve_text_input(workflow, value)
                if resolved is not None:
                    value = resolved
                else:
                    value = value[0]
            try:
                text = str(value)
            except Exception:
                text = None
            if text in (None, ""):
                return None
            return text.replace(",", "/")

        def _collect_pairs(inputs: dict[str, Any]) -> dict[str, str]:
            collected: dict[str, str] = {}

            def _maybe_add(raw_key: Any, raw_value: Any) -> None:
                key = _normalize_key(raw_key)
                if not key:
                    return
                value = _normalize_value(raw_value)
                if value is None:
                    return
                collected[key] = value

            # Legacy single key/value pairs some nodes may expose
            _maybe_add(inputs.get("key"), inputs.get("value"))
            _maybe_add(inputs.get("label"), inputs.get("text"))

            # Primary CreateExtraMetaDataUniversal fields
            for idx in range(1, 5):
                _maybe_add(inputs.get(f"key{idx}"), inputs.get(f"value{idx}"))

            return collected

        def _resolve_chain(node_id: str, visited: set[str]) -> dict[str, str]:
            if not node_id or node_id in visited:
                return {}
            visited.add(node_id)

            node = workflow.get(node_id)
            if not node:
                return {}

            inputs = node.get("inputs", {})
            class_type = node.get("class_type", "")

            merged: dict[str, str] = {}
            chained_ref = inputs.get("extra_metadata")
            if isinstance(chained_ref, list) and chained_ref:
                merged.update(_resolve_chain(str(chained_ref[0]), visited))

            if "ExtraMetaData" in class_type:
                merged.update(_collect_pairs(inputs))

            return merged

        root_id = str(extra_metadata_ref[0])
        return _resolve_chain(root_id, set())

    @staticmethod
    def extract_expected_metadata_for_save_node(workflow: dict, save_node_id: str, save_node: dict) -> dict[str, Any]:
        """Extract complete expected metadata for a specific Save Image node by tracing its connections."""
        expected = {
            "save_node_id": save_node_id,
            "filename_prefix": "",
            "filename_patterns": [],
            "file_format": "png",
        }

        # Get save node settings
        save_inputs = save_node.get("inputs", {})
        expected["filename_prefix"] = WorkflowAnalyzer.resolve_filename_prefix(workflow, save_inputs.get("filename_prefix", ""))

        # Extract filename patterns and a deterministic leaf marker for this save node's prefix
        if expected["filename_prefix"]:
            prefix_tokens = WorkflowAnalyzer._extract_prefix_tokens(expected["filename_prefix"])
            expected["filename_patterns"].extend(prefix_tokens)
            if prefix_tokens:
                expected["filename_prefix_leaf"] = prefix_tokens[-1]
                expected["filename_prefix_tokens"] = prefix_tokens

        expected["file_format"] = save_inputs.get("file_format", "png")
        expected["save_workflow_json"] = save_inputs.get("save_workflow_json", False)
        expected["include_lora_summary"] = save_inputs.get("include_lora_summary", False)
        expected["max_jpeg_exif_kb"] = save_inputs.get("max_jpeg_exif_kb", 60)
        expected["guidance_as_cfg"] = save_inputs.get("guidance_as_cfg", False)
        expected["civitai_sampler"] = save_inputs.get("civitai_sampler", False)
        expected["sampler_selection_method"] = save_inputs.get("sampler_selection_method", "Farthest")
        expected["sampler_selection_node_id"] = save_inputs.get("sampler_selection_node_id")

        # Trace to sampler (may need to trace through intermediate nodes like VAEDecode)
        # Use strict tracing to find ONLY samplers connected to this save node
        connected_samplers = WorkflowAnalyzer.get_connected_sampler_chain(workflow, save_node_id)

        sampler_id = None
        sampler_node = None

        def _normalize_selection_node_id(raw_value: Any) -> str | None:
            if raw_value in (None, "", 0, -1):
                return None
            if isinstance(raw_value, list | tuple):
                if not raw_value:
                    return None
                return str(raw_value[0])
            try:
                return str(raw_value)
            except Exception:
                return None

        selection_method = expected.get("sampler_selection_method", "Farthest")
        selection_node_id = _normalize_selection_node_id(expected.get("sampler_selection_node_id"))

        if not connected_samplers:
            # No samplers found in chain
            pass
        elif len(connected_samplers) == 1:
            # Only one sampler, use it
            sampler_id, sampler_node, _ = connected_samplers[0]
        else:
            # Multiple samplers in chain, use selection method
            if selection_method == "By node ID" and selection_node_id:
                # Find specific node in the connected chain
                target_id = str(selection_node_id)
                for nid, node, distance in connected_samplers:
                    if nid == target_id:
                        sampler_id = nid
                        sampler_node = node
                        break
            if not sampler_node:
                reverse = selection_method == "Farthest"
                if selection_method not in {"Farthest", "Nearest"}:
                    reverse = False
                sorted_candidates = sorted(connected_samplers, key=lambda entry: entry[2], reverse=reverse)
                sampler_id, sampler_node, _ = sorted_candidates[0]

            # Fallback if selection failed but we have samplers
            if not sampler_node and connected_samplers:
                sampler_id, sampler_node, _ = connected_samplers[0]

        if not sampler_node:
            return expected

        expected["sampler_node_id"] = sampler_id
        expected["sampler_class_type"] = sampler_node.get("class_type")

        # Extract sampler parameters
        sampler_inputs = sampler_node.get("inputs", {})
        seed_input = sampler_inputs.get("seed", sampler_inputs.get("noise_seed"))
        expected["seed"] = WorkflowAnalyzer.resolve_seed_value(workflow, seed_input)
        if expected["seed"] is None:
            expected["seed"] = WorkflowAnalyzer._resolve_noise_seed(workflow, sampler_inputs.get("noise"))
        if expected["seed"] is not None:
            expected["seed"] = str(expected["seed"])
        expected["steps"] = sampler_inputs.get("steps")
        expected["cfg"] = sampler_inputs.get("cfg")
        expected["sampler_name"] = sampler_inputs.get("sampler_name")
        expected["scheduler"] = sampler_inputs.get("scheduler")
        expected["denoise"] = sampler_inputs.get("denoise")
        expected["guidance"] = WorkflowAnalyzer.resolve_guidance_value(workflow, sampler_inputs)

        scheduler_meta = WorkflowAnalyzer._resolve_scheduler_metadata(workflow, sampler_inputs.get("sigmas"))
        for key in ("steps", "scheduler", "denoise"):
            if scheduler_meta.get(key) is not None and expected.get(key) in (None, ""):
                expected[key] = scheduler_meta[key]

        if not expected.get("sampler_name"):
            sampler_choice = WorkflowAnalyzer._resolve_sampler_choice(workflow, sampler_inputs.get("sampler"))
            if sampler_choice:
                expected["sampler_name"] = sampler_choice

        if sampler_inputs.get("positive"):
            expected["positive_prompt"] = WorkflowAnalyzer.resolve_text_input(workflow, sampler_inputs.get("positive"))
        if expected.get("positive_prompt") is None:
            expected["positive_prompt"] = WorkflowAnalyzer.resolve_text_input(
                workflow,
                sampler_inputs.get("guider"),
            )

        if sampler_inputs.get("negative"):
            neg_val = WorkflowAnalyzer.resolve_text_input(workflow, sampler_inputs.get("negative"))
            # Skip if negative prompt is identical to positive prompt.
            # This can occur when workflows share text nodes or when certain sampler configurations
            # reuse the positive prompt reference. Logging this case helps debug unexpected behavior.
            # Note: We only perform the duplicate check for non-empty negative prompts; empty/falsy
            # negative prompts are silently skipped since they carry no semantic content to validate.
            if neg_val:
                if neg_val == expected.get("positive_prompt"):
                    logger.warning("negative prompt is identical to positive prompt for sampler node %s", sampler_id)
                    expected["negative_prompt_skipped_duplicate"] = True
                    expected["negative_prompt"] = None
                else:
                    expected["negative_prompt"] = neg_val

        # Trace to loader (could be through 'model' or 'sdxl_tuple' input)
        loader_id, loader_node = None, None
        for input_key in ["model", "sdxl_tuple"]:
            loader_id, loader_node = WorkflowAnalyzer.trace_node_input(workflow, sampler_id, input_key)
            if loader_node:
                break

        if loader_node:
            expected["loader_node_id"] = loader_id
            expected["loader_class_type"] = loader_node.get("class_type")

            loader_inputs = loader_node.get("inputs", {})

            loader_positive = WorkflowAnalyzer.resolve_text_input(workflow, loader_inputs.get("positive"))
            if loader_positive:
                expected["positive_prompt"] = loader_positive

            loader_negative = WorkflowAnalyzer.resolve_text_input(workflow, loader_inputs.get("negative"))
            if loader_negative:
                expected["negative_prompt"] = loader_negative

            # Inline LoRA (for workflows using loader-level LoRA blend)
            inline_lora = loader_inputs.get("lora_name")
            if inline_lora and inline_lora != "None":
                model_strength, clip_strength = WorkflowAnalyzer._resolve_strength_pair(loader_inputs)
                WorkflowAnalyzer._add_lora_entry(
                    expected.setdefault("lora_stack", []),
                    inline_lora,
                    model_strength,
                    clip_strength,
                )

            # T5/CLIP prompts for dual CLIP
            expected["t5_prompt"] = WorkflowAnalyzer.resolve_text_input(workflow, loader_inputs.get("t5xxl"))
            expected["clip_prompt"] = WorkflowAnalyzer.resolve_text_input(workflow, loader_inputs.get("clip_l"))

            # LoRA stack node reference
            lora_stack_ref = loader_inputs.get("lora_stack")
            if isinstance(lora_stack_ref, list) and len(lora_stack_ref) >= 1:
                lora_stack_id = str(lora_stack_ref[0])
                stack_entries = WorkflowAnalyzer.extract_lora_stack_info(workflow, lora_stack_id)
                if stack_entries:
                    target = expected.setdefault("lora_stack", [])
                    for entry in stack_entries:
                        WorkflowAnalyzer._add_lora_entry(
                            target,
                            entry.get("name"),
                            entry.get("model_strength"),
                            entry.get("clip_strength"),
                        )

        model_info = WorkflowAnalyzer.resolve_model_hierarchy(workflow, sampler_id)

        if model_info.get("model_name"):
            expected["model_name"] = model_info["model_name"]
        if model_info.get("clip_model_name"):
            expected["clip_model_name"] = model_info["clip_model_name"]
        if model_info.get("clip_skip") is not None:
            expected["clip_skip"] = model_info["clip_skip"]
        if model_info.get("weight_dtype"):
            expected["weight_dtype"] = model_info["weight_dtype"]
        if model_info.get("lora_stack"):
            merged = expected.get("lora_stack", []) + model_info["lora_stack"]
            expected["lora_stack"] = WorkflowAnalyzer._dedupe_lora_entries(merged)
            if not expected.get("include_lora_summary"):
                expected["include_lora_summary"] = True
        elif expected.get("lora_stack"):
            expected["lora_stack"] = WorkflowAnalyzer._dedupe_lora_entries(expected["lora_stack"])
            if not expected.get("include_lora_summary"):
                expected["include_lora_summary"] = True

        if model_info.get("base_shift") is not None:
            expected["base_shift"] = model_info["base_shift"]
        if model_info.get("max_shift") is not None:
            expected["max_shift"] = model_info["max_shift"]

        vae_name = WorkflowAnalyzer.resolve_vae_name(workflow, save_node_id)
        if vae_name:
            expected["vae_name"] = vae_name
        elif model_info.get("vae_name"):
            expected["vae_name"] = model_info["vae_name"]

        latent_attrs = WorkflowAnalyzer.resolve_latent_attributes(workflow, sampler_inputs)
        if latent_attrs:
            if latent_attrs.get("image_width"):
                expected["image_width"] = latent_attrs["image_width"]
            if latent_attrs.get("image_height"):
                expected["image_height"] = latent_attrs["image_height"]
            if latent_attrs.get("batch_size") is not None:
                expected["batch_size"] = latent_attrs["batch_size"]

        # Resolve extra metadata
        extra_metadata_ref = save_inputs.get("extra_metadata")
        if extra_metadata_ref:
            expected["extra_metadata"] = WorkflowAnalyzer.resolve_extra_metadata(workflow, extra_metadata_ref)

        return expected

    @staticmethod
    def extract_expected_metadata(workflow: dict, workflow_name: str) -> dict[str, Any]:
        """Extract expected metadata fields from workflow."""
        expected = {
            "workflow_name": workflow_name,
            "has_save_node": False,
            "save_nodes": [],
            "filename_patterns": [],
        }

        # Find save nodes (there can be multiple)
        save_nodes = WorkflowAnalyzer.find_save_nodes(workflow)
        if save_nodes:
            expected["has_save_node"] = True

            # Extract complete metadata expectations for each save node
            for save_node_id, save_node in save_nodes:
                save_node_expected = WorkflowAnalyzer.extract_expected_metadata_for_save_node(workflow, save_node_id, save_node)
                expected["save_nodes"].append(save_node_expected)

            # Extract filename patterns from all save nodes
            expected["filename_patterns"] = WorkflowAnalyzer.extract_filename_patterns(workflow)
            expected["filename_leaf_markers"] = [
                node["filename_prefix_leaf"].lower()
                for node in expected["save_nodes"]
                if node.get("filename_prefix_leaf")
            ]

        return expected


class MetadataValidator:
    """Validates image metadata against expected values."""

    # Compiled regex patterns for known metadata key patterns (compiled once for efficiency)
    KNOWN_KEY_PATTERNS = [
        re.compile(r"^Lora_\d+$"),
        re.compile(r"^Lora_\d+\s+.+$"),  # Matches "Lora_0 Model name", "Lora_0 Model hash", etc.
        re.compile(r"^Embedding_\d+$"),
        re.compile(r"^Embedding_\d+\s+.+$"),  # Matches "Embedding_0 name", "Embedding_0 hash", etc.
        re.compile(r"^CLIP_\d+\s+.+$"),  # Matches "CLIP_1 Model name", etc.
    ]

    # Fields that should always be present in every generated image metadata
    # These are the core fields that the validation script MUST check
    REQUIRED_CORE_FIELDS = {
        "Seed",
        "Steps",
        "Sampler",
        "Model",
        "Model hash",
        "Denoise",
        "Metadata generator version",
    }

    # At least one of these should be present (CFG for SD, Guidance for Flux)
    REQUIRED_CFG_OR_GUIDANCE = {"CFG scale", "Guidance"}

    # Fields that are informational and don't need validation
    # These are summary/display fields that are not testable against expected values
    INFORMATIONAL_FIELDS = {
        "Metadata Fallback",
        "LoRAs",  # Summary field, individual LoRAs validated separately
        "Samplers",  # Summary field
    }

    def __init__(
        self,
        workflow_dir: Path,
        output_dir: Path,
        comfyui_models_path: Path | None = None,
        verbose: bool = False,
    ):
        self.workflow_dir = workflow_dir
        self.output_dir = output_dir
        self.comfyui_models_path = comfyui_models_path
        self.results = []
        self.verbose = verbose

    @staticmethod
    def _record_check_detail(
        result: dict,
        field_name: str,
        status: str,
        expected: Any | None = None,
        actual: Any | None = None,
        message: str | None = None,
    ) -> None:
        detail: dict[str, Any] = {"field": field_name, "status": status}
        if expected is not None:
            detail["expected"] = expected
        if actual is not None:
            detail["actual"] = actual
        if message:
            detail["message"] = message
        result.setdefault("check_details", []).append(detail)

    @staticmethod
    def _is_baked_vae(fields: dict[str, Any]) -> bool:
        """Return True when metadata represents an inline/baked VAE."""
        vae_value = fields.get("VAE")
        if isinstance(vae_value, str):
            return vae_value.strip().lower() == "baked vae"
        return False

    def _extract_json_value(self, text: str) -> str:
        """Extract JSON object or array from the beginning of text."""
        text = text.strip()
        if not text:
            return text

        # Track brace/bracket depth to find where JSON ends
        if text[0] == "{":
            depth = 0
            in_string = False
            escape_next = False

            for i, char in enumerate(text):
                if escape_next:
                    escape_next = False
                    continue

                if char == "\\":
                    escape_next = True
                    continue

                if char == '"' and not escape_next:
                    in_string = not in_string
                    continue

                if not in_string:
                    if char == "{":
                        depth += 1
                    elif char == "}":
                        depth -= 1
                        if depth == 0:
                            return text[: i + 1]

        elif text[0] == "[":
            depth = 0
            in_string = False
            escape_next = False

            for i, char in enumerate(text):
                if escape_next:
                    escape_next = False
                    continue

                if char == "\\":
                    escape_next = True
                    continue

                if char == '"' and not escape_next:
                    in_string = not in_string
                    continue

                if not in_string:
                    if char == "[":
                        depth += 1
                    elif char == "]":
                        depth -= 1
                        if depth == 0:
                            return text[: i + 1]

        return text

    def parse_parameters_string(self, params_str: str) -> dict[str, str]:
        """Parse the parameters string into a dictionary of fields."""
        if not params_str:
            return {}

        # Define known metadata keys
        known_keys = {
            "Steps",
            "Sampler",
            "CFG scale",
            "Seed",
            "Size",
            "Model",
            "Model hash",
            "VAE",
            "VAE hash",
            "Clip skip",
            "Denoise",
            "Shift",
            "Max shift",
            "Base shift",
            "Guidance",
            "Scheduler",
            "Hashes",
            "Metadata generator version",
            "Batch index",
            "Batch size",
            "Metadata Fallback",
            "LoRAs",
            "Weight dtype",
            "Samplers",
            "T5 Prompt",
            "CLIP Prompt",
            "CLIP_1 Model name",
            "CLIP_2 Model name",
        }

        prompt_header_keys = {"T5 Prompt", "CLIP Prompt", "Positive prompt", "Negative prompt"}
        metadata_start_keys = known_keys - prompt_header_keys

        fields = {}
        lines = params_str.strip().split("\n")
        metadata_start_idx = 0

        # Look for where actual metadata starts
        for idx, line in enumerate(lines):
            match = re.match(r"^([A-Za-z0-9 _\-]+):\s*(.*)", line)
            if match:
                potential_key = match.group(1).strip()
                is_metadata_key = potential_key in metadata_start_keys or any(
                    pattern.match(potential_key) for pattern in self.KNOWN_KEY_PATTERNS
                )
                if is_metadata_key:
                    metadata_start_idx = idx
                    break

        # Capture prompt headers
        header_fields: dict[str, str] = {}
        current_header_key: str | None = None
        positive_lines: list[str] = []
        for line in lines[:metadata_start_idx]:
            stripped_line = line.strip()
            match = re.match(r"^([A-Za-z0-9 _\-]+):\s*(.*)", line)
            if match:
                potential_key = match.group(1).strip()
                if potential_key in prompt_header_keys:
                    header_fields[potential_key] = match.group(2).strip()
                    current_header_key = potential_key
                else:
                    current_header_key = None
                continue

            if current_header_key and stripped_line:
                header_fields[current_header_key] = "\n".join(filter(None, [header_fields[current_header_key], stripped_line]))
            elif stripped_line:
                positive_lines.append(stripped_line)

        if positive_lines and "Positive prompt" not in header_fields:
            header_fields["Positive prompt"] = "\n".join(positive_lines).strip()

        fields.update(header_fields)

        # Join metadata lines
        if metadata_start_idx < len(lines):
            metadata_text = "\n".join(lines[metadata_start_idx:])
        else:
            metadata_text = params_str

        # Detect format
        escaped_keys = [re.escape(k) for k in known_keys]
        comma_pattern = re.compile(r",\s*(?:" + "|".join(escaped_keys) + r"):")
        newline_pattern = re.compile(r"\n\s*(?:" + "|".join(escaped_keys) + r"):")

        comma_key_count = len(comma_pattern.findall(metadata_text))
        newline_key_count = len(newline_pattern.findall(metadata_text))

        use_comma_format = comma_key_count > newline_key_count

        if use_comma_format:
            all_patterns = list(known_keys)
            escaped_keys = [re.escape(k) + r":" for k in all_patterns]
            split_pattern = r",\s*(?=" + "|".join(escaped_keys) + r"|(?:Lora_|Embedding_|CLIP_)\d+\s+[^:]+:)"
            parts = re.split(split_pattern, metadata_text)

            for part in parts:
                part = part.strip()
                if not part:
                    continue

                match = re.match(r"^([A-Za-z0-9 _\-]+):\s*(.*)", part, re.DOTALL)
                if match:
                    key = match.group(1).strip()
                    value = match.group(2).strip()

                    if key == "Hashes":
                        value = self._extract_json_value(value)

                    is_known = key in known_keys or any(pattern.match(key) for pattern in self.KNOWN_KEY_PATTERNS)
                    if is_known:
                        fields[key] = value
        else:
            # Parse newline-separated format
            current_key = None
            current_value = []

            for line in lines[metadata_start_idx:]:
                match = re.match(r"^([A-Za-z0-9 _\-]+):\s*(.*)", line)
                if match:
                    potential_key = match.group(1).strip()
                    value = match.group(2)

                    if current_key:
                        fields[current_key] = "\n".join(current_value).strip()

                    current_key = potential_key
                    current_value = []
                    if value:
                        current_value.append(value)
                    continue

                if current_key:
                    if line.strip():
                        current_value.append(line.strip())

            if current_key:
                fields[current_key] = "\n".join(current_value).strip()

        self._capture_additional_fields(metadata_text, fields)

        return fields

    @staticmethod
    def _capture_additional_fields(metadata_text: str, fields: dict) -> None:
        """Capture colon-delimited fields not covered by known key parsing."""

        if not metadata_text:
            return

        pattern = re.compile(r"^([A-Za-z0-9][A-Za-z0-9 _\-/]{0,80})\s*:\s*(.+)$")
        candidates = metadata_text.replace("\r", "").splitlines()
        candidates.extend(chunk.strip() for chunk in metadata_text.split(",") if chunk.strip())

        for raw_line in candidates:
            match = pattern.match(raw_line.strip())
            if not match:
                continue
            key = match.group(1).strip()
            if not key or key in fields:
                continue
            value = match.group(2).strip()
            if not value:
                continue
            fields[key] = value

    def _validate_expected_fields(self, fields: dict, expected_metadata: dict, result: dict):
        """Comprehensively validate that actual metadata matches all expected values."""

        check_details = result.setdefault("check_details", [])
        recorded_fields: set[str] = set()

        def normalize_value(value: Any) -> str:
            if value is None or value == "":
                return "N/A"
            return str(value)

        def normalize_text(value: Any) -> str:
            if value is None or value == "":
                return ""
            if isinstance(value, str):
                return value.strip()
            return str(value).strip()

        def add_detail(
            field_name: str,
            status: str,
            expected: Any = None,
            actual: Any = None,
            message: str | None = None,
        ):
            detail: dict[str, Any] = {"field": field_name, "status": status}
            if expected is not None:
                detail["expected"] = expected
            if actual is not None:
                detail["actual"] = actual
            if message:
                detail["message"] = message
            check_details.append(detail)
            if status != "info":
                recorded_fields.add(field_name)

        def mark_pass(field_name: str, expected: Any, actual: Any):
            add_detail(field_name, "pass", expected, actual)

        def mark_fail(field_name: str, expected: Any, actual: Any, message: str):
            result["errors"].append(message)
            add_detail(field_name, "fail", expected, actual, message)

        def mark_warn(field_name: str, expected: Any, actual: Any, message: str):
            result["warnings"].append(message)
            add_detail(field_name, "warn", expected, actual, message)

        def compare_numeric_field(field_name: str, expected: Any):
            expected_str = str(expected)
            actual_value = fields.get(field_name)
            actual_str = normalize_value(actual_value)
            if actual_value in (None, ""):
                message = f"{field_name} missing, expected '{expected_str}'"
                mark_fail(field_name, expected_str, actual_str, message)
                return
            try:
                expected_float = float(expected_str)
                actual_float = float(str(actual_value))
                if abs(expected_float - actual_float) > 0.0001:
                    message = f"{field_name} mismatch: expected '{expected_str}', got '{actual_str}'"
                    mark_fail(field_name, expected_str, actual_str, message)
                else:
                    mark_pass(field_name, expected_str, actual_str)
            except (ValueError, TypeError):
                if str(actual_value) != expected_str:
                    message = f"{field_name} mismatch: expected '{expected_str}', got '{actual_str}'"
                    mark_fail(field_name, expected_str, actual_str, message)
                else:
                    mark_pass(field_name, expected_str, actual_str)

        def compare_string_field(field_name: str, expected: Any):
            expected_str = normalize_text(expected)
            actual_value = fields.get(field_name)
            actual_str = normalize_text(actual_value)
            if actual_value in (None, ""):
                message = f"{field_name} missing, expected '{expected_str or 'value'}'"
                mark_fail(field_name, expected_str or "value", normalize_value(actual_value), message)
            elif actual_str != expected_str:
                message = f"{field_name} mismatch: expected '{expected_str}', got '{actual_str}'"
                mark_fail(field_name, expected_str, actual_str, message)
            else:
                mark_pass(field_name, expected_str, actual_str)

        def _normalize_sampler_token(value: Any) -> str | None:
            if value is None:
                return None
            if isinstance(value, list | tuple):
                return None
            try:
                token = str(value).strip()
            except Exception:
                return None
            if not token or token.lower() == "none":
                return None
            return token

        def _normalize_scheduler_value(value: Any) -> str | None:
            token = _normalize_sampler_token(value)
            if token:
                return token.lower()
            return None

        def _clean_sampler_identifier(value: str | None) -> str | None:
            if not value:
                return None
            value = value.strip()
            if value.startswith("<") and " object at 0x" in value:
                return None
            return value

        def _compose_non_civitai_sampler(sampler_name: str | None, scheduler_token: str | None) -> str | None:
            if sampler_name and scheduler_token:
                return f"{sampler_name}_{scheduler_token}"
            if sampler_name:
                return sampler_name
            if scheduler_token:
                return scheduler_token
            return None

        def _sampler_with_karras(base: str, scheduler_token: str | None) -> str:
            if scheduler_token == "karras":
                return f"{base} Karras"
            return base

        def _sampler_with_karras_or_exponential(base: str, scheduler_token: str | None) -> str:
            if scheduler_token == "karras":
                return f"{base} Karras"
            if scheduler_token == "exponential":
                return f"{base} Exponential"
            return base

        def _compose_civitai_sampler(sampler_name: str | None, scheduler_token: str | None) -> str | None:
            sampler_clean = _clean_sampler_identifier(sampler_name)
            if not sampler_clean:
                return scheduler_token

            sampler_l = sampler_clean.lower()
            match sampler_l:
                case "euler" | "euler_cfg_pp":
                    return "Euler"
                case "euler_ancestral" | "euler_ancestral_cfg_pp":
                    return "Euler a"
                case "heun" | "heunpp2":
                    return "Heun"
                case "dpm_2":
                    return _sampler_with_karras("DPM2", scheduler_token)
                case "dpm_2_ancestral":
                    return _sampler_with_karras("DPM2 a", scheduler_token)
                case "lms":
                    return _sampler_with_karras("LMS", scheduler_token)
                case "dpm_fast":
                    return "DPM fast"
                case "dpm_adaptive":
                    return "DPM adaptive"
                case "dpmpp_2s_ancestral":
                    return _sampler_with_karras("DPM++ 2S a", scheduler_token)
                case "dpmpp_sde" | "dpmpp_sde_gpu":
                    return _sampler_with_karras("DPM++ SDE", scheduler_token)
                case "dpmpp_2m":
                    return _sampler_with_karras("DPM++ 2M", scheduler_token)
                case "dpmpp_2m_sde" | "dpmpp_2m_sde_gpu":
                    return _sampler_with_karras("DPM++ 2M SDE", scheduler_token)
                case "dpmpp_3m_sde" | "dpmpp_3m_sde_gpu":
                    return _sampler_with_karras_or_exponential("DPM++ 3M SDE", scheduler_token)
                case "lcm":
                    return "LCM"
                case "ddim":
                    return "DDIM"
                case "plms":
                    return "PLMS"
                case "uni_pc" | "uni_pc_bh2":
                    return "UniPC"

            if not scheduler_token or scheduler_token == "normal":
                return sampler_clean
            return f"{sampler_clean}_{scheduler_token}"

        # Validate seed
        # ComfyUI generates seeds with varying lengths (13-18 digits) depending on the
        # node implementation and platform-specific RNG behavior.
        if expected_metadata.get("seed") is not None:
            expected_seed = str(expected_metadata["seed"])
            actual_seed = fields.get("Seed", "")
            actual_seed_str = normalize_value(actual_seed)
            if expected_seed == "-1":
                # Accept 13 to 18 digits for random seed
                if actual_seed and 13 <= len(str(actual_seed)) <= 18 and str(actual_seed).isdigit():
                    mark_pass("Seed", "13-18 digit random", actual_seed_str)
                else:
                    mark_fail(
                        "Seed",
                        "13-18 digit random",
                        actual_seed_str,
                        f"Seed format mismatch: expected 13-18 digit random seed, got '{actual_seed_str}'",
                    )
            else:
                compare_numeric_field("Seed", expected_seed)

        # Validate steps
        if expected_metadata.get("steps") is not None:
            compare_numeric_field("Steps", expected_metadata["steps"])

        # Validate CFG (respect guidance_as_cfg toggle)
        if expected_metadata.get("cfg") is not None:
            cfg_expected = expected_metadata["cfg"]
            if expected_metadata.get("guidance_as_cfg") and expected_metadata.get("guidance") is not None:
                cfg_expected = expected_metadata["guidance"]
            compare_numeric_field("CFG scale", cfg_expected)

        # Validate Sampler by mirroring capture.py behavior.
        civitai_sampler_enabled = expected_metadata.get("civitai_sampler", False)
        sampler_token = _clean_sampler_identifier(_normalize_sampler_token(expected_metadata.get("sampler_name")))
        scheduler_token = _normalize_scheduler_value(expected_metadata.get("scheduler"))
        expected_sampler_value = (
            _compose_civitai_sampler(sampler_token, scheduler_token)
            if civitai_sampler_enabled
            else _compose_non_civitai_sampler(sampler_token, scheduler_token)
        )

        actual_sampler = normalize_text(fields.get("Sampler"))
        if expected_sampler_value:
            if not actual_sampler:
                mark_fail("Sampler", expected_sampler_value, "N/A", "Sampler field missing")
            elif actual_sampler.lower() != expected_sampler_value.lower():
                mismatch_msg = (
                    f"Sampler mismatch (Civitai strict): expected '{expected_sampler_value}', got '{actual_sampler}'"
                    if civitai_sampler_enabled
                    else f"Sampler mismatch: expected '{expected_sampler_value}', got '{actual_sampler}'"
                )
                mark_fail("Sampler", expected_sampler_value, actual_sampler, mismatch_msg)
            else:
                mark_pass("Sampler", expected_sampler_value, actual_sampler)


        # Validate denoise and guidance
        if expected_metadata.get("denoise") is not None:
            compare_numeric_field("Denoise", expected_metadata["denoise"])

        # Only validate Guidance if NOT using guidance_as_cfg
        if expected_metadata.get("guidance") is not None and not expected_metadata.get("guidance_as_cfg"):
            compare_numeric_field("Guidance", expected_metadata["guidance"])

        # Validate model name (basename only)
        if expected_metadata.get("model_name"):
            actual_model = fields.get("Model")
            expected_model_path = str(expected_metadata["model_name"]).replace("\\", "/")
            expected_model_basename = Path(expected_model_path).stem
            actual_model_basename = Path(actual_model).stem if actual_model else ""
            if actual_model_basename:
                if actual_model_basename == expected_model_basename:
                    mark_pass("Model", expected_model_basename, actual_model_basename)
                else:
                    mark_fail(
                        "Model",
                        expected_model_basename,
                        actual_model_basename,
                        f"Model mismatch: expected '{expected_model_basename}', got '{actual_model_basename}'",
                    )
            else:
                message = f"Model missing, expected '{expected_model_basename}'"
                mark_fail("Model", expected_model_basename, "N/A", message)

        # Validate VAE name
        if expected_metadata.get("vae_name") and expected_metadata["vae_name"] != "Baked VAE":
            actual_vae = fields.get("VAE")
            expected_vae_basename = Path(str(expected_metadata["vae_name"])).stem
            actual_vae_basename = Path(actual_vae).stem if actual_vae else ""
            if actual_vae_basename:
                if actual_vae_basename == expected_vae_basename:
                    mark_pass("VAE", expected_vae_basename, actual_vae_basename)
                else:
                    mark_fail(
                        "VAE",
                        expected_vae_basename,
                        actual_vae_basename,
                        f"VAE mismatch: expected '{expected_vae_basename}', got '{actual_vae_basename}'",
                    )
            else:
                mark_fail("VAE", expected_vae_basename, "N/A", f"VAE missing, expected '{expected_vae_basename}'")

        # Validate clip skip
        if expected_metadata.get("clip_skip") is not None:
            compare_numeric_field("Clip skip", abs(int(expected_metadata["clip_skip"])))

        # Validate image dimensions
        if expected_metadata.get("image_width") and expected_metadata.get("image_height"):
            expected_size = f"{expected_metadata['image_width']}x{expected_metadata['image_height']}"
            actual_size = fields.get("Size")
            actual_size_str = normalize_value(actual_size)
            if actual_size in (None, ""):
                message = f"Size missing, expected '{expected_size}'"
                mark_fail("Size", expected_size, actual_size_str, message)
            elif actual_size_str != expected_size:
                message = f"Size mismatch: expected '{expected_size}', got '{actual_size_str}'"
                mark_warn("Size", expected_size, actual_size_str, message)
            else:
                mark_pass("Size", expected_size, actual_size_str)

        expected_loras = expected_metadata.get("lora_stack")
        if expected_loras:
            lora_indices: set[int] = set()
            for key in fields.keys():
                match = re.match(r"Lora_(\d+) Model name", key)
                if match:
                    lora_indices.add(int(match.group(1)))

            actual_lora_count = len(lora_indices)
            expected_lora_count = len(expected_loras)
            if actual_lora_count == expected_lora_count:
                mark_pass("LoRA count", expected_lora_count, actual_lora_count)
            else:
                mark_fail(
                    "LoRA count",
                    expected_lora_count,
                    actual_lora_count,
                    f"LoRA count mismatch: expected {expected_lora_count} LoRAs, got {actual_lora_count}",
                )

            for idx, expected_lora in enumerate(expected_loras):
                name_key = f"Lora_{idx} Model name"
                model_str_key = f"Lora_{idx} Strength model"
                clip_str_key = f"Lora_{idx} Strength clip"

                if name_key in fields:
                    actual_name = fields[name_key]
                    actual_basename = Path(actual_name).stem if actual_name else ""
                    expected_basename = Path(expected_lora["name"]).stem
                    if actual_basename == expected_basename:
                        mark_pass(f"LoRA {idx} name", expected_basename, actual_basename)
                    else:
                        mark_fail(
                            f"LoRA {idx} name",
                            expected_basename,
                            actual_basename,
                            f"LoRA {idx} name mismatch: expected '{expected_basename}', got '{actual_basename}'",
                        )

                    # Validate model strength only if key is present with a non-None value;
                    # the 'in' check differentiates missing keys from explicit None, while allowing 0 as valid
                    if "model_strength" in expected_lora and expected_lora["model_strength"] is not None:  # Allows 0 as valid strength
                        if model_str_key in fields:
                            compare_numeric_field(model_str_key, expected_lora["model_strength"])
                        else:
                            mark_fail(
                                model_str_key,
                                expected_lora["model_strength"],
                                "N/A",
                                f"{model_str_key} not present in metadata",
                            )

                    expected_clip_strength = expected_lora.get("clip_strength")
                    if expected_clip_strength is not None:
                        if clip_str_key in fields:
                            compare_numeric_field(clip_str_key, expected_clip_strength)
                        else:
                            mark_fail(
                                clip_str_key,
                                expected_clip_strength,
                                "N/A",
                                f"{clip_str_key} not present in metadata",
                            )
                else:
                    mark_fail(
                        f"LoRA {idx} name",
                        Path(expected_lora["name"]).stem,
                        "N/A",
                        f"Expected LoRA {idx} ('{expected_lora['name']}') not found in metadata",
                    )

                hash_key = f"Lora_{idx} Model hash"
                if hash_key in fields:
                    hash_value = normalize_value(fields[hash_key])
                    if hash_value in ("", "N/A"):
                        mark_fail(
                            hash_key,
                            "computed hash",
                            hash_value,
                            f"{hash_key} missing hash value",
                        )
                    else:
                        mark_pass(hash_key, "hash present", hash_value)
                else:
                    mark_fail(
                        hash_key,
                        "computed hash",
                        "N/A",
                        f"{hash_key} not present in metadata",
                    )

        # Validate Extra Metadata
        if expected_metadata.get("extra_metadata"):
            for key, expected_val in expected_metadata["extra_metadata"].items():
                if key in fields:
                    actual_val = fields[key]
                    if str(actual_val) == str(expected_val):
                        mark_pass(f"Extra: {key}", expected_val, actual_val)
                    else:
                        mark_fail(
                            f"Extra: {key}",
                            expected_val,
                            actual_val,
                            f"Extra metadata '{key}' mismatch: expected '{expected_val}', got '{actual_val}'",
                        )
                else:
                    mark_fail(f"Extra: {key}", expected_val, "N/A", f"Extra metadata field '{key}' missing")

        # Prompts
        def _dual_prompt_satisfies_positive() -> bool:
            t5_actual = normalize_text(fields.get("T5 Prompt"))
            clip_actual = normalize_text(fields.get("CLIP Prompt"))
            if not (t5_actual or clip_actual):
                return False
            expected_t5 = normalize_text(expected_metadata.get("t5_prompt"))
            expected_clip = normalize_text(expected_metadata.get("clip_prompt"))

            t5_ok = not expected_t5 or t5_actual == expected_t5
            clip_ok = not expected_clip or clip_actual == expected_clip
            if t5_ok and clip_ok:
                combined_expected = " / ".join(filter(None, [expected_t5, expected_clip])) or "dual prompt"
                combined_actual = " / ".join(filter(None, [t5_actual, clip_actual]))
                mark_pass("Positive prompt (dual)", combined_expected, combined_actual)
                return True
            return False

        if expected_metadata.get("positive_prompt") is not None:
            actual_positive = normalize_text(fields.get("Positive prompt"))
            if actual_positive:
                compare_string_field("Positive prompt", expected_metadata.get("positive_prompt"))
            elif not _dual_prompt_satisfies_positive():
                message = "Positive prompt missing from metadata"
                mark_fail("Positive prompt", expected_metadata.get("positive_prompt"), "N/A", message)

        negative_prompt_expected = expected_metadata.get("negative_prompt")
        if negative_prompt_expected is not None:
            compare_string_field("Negative prompt", negative_prompt_expected)

        metadata_version = normalize_text(fields.get("Metadata generator version"))
        if metadata_version:
            mark_pass("Metadata generator version", "present", metadata_version)
        else:
            message = "Metadata generator version missing from metadata"
            mark_fail("Metadata generator version", "present", "N/A", message)

        # Hash fields
        if expected_metadata.get("model_name"):
            actual_model_hash = fields.get("Model hash")
            actual_model_hash_str = normalize_value(actual_model_hash)
            if actual_model_hash in (None, ""):
                mark_fail("Model hash", "computed hash", actual_model_hash_str, "Model hash missing")
            elif actual_model_hash_str == "N/A":
                message = "Model hash is 'N/A' - should be computed"
                mark_fail("Model hash", "computed hash", actual_model_hash_str, message)
            else:
                mark_pass("Model hash", "hash present", actual_model_hash_str)

        if expected_metadata.get("vae_name"):
            is_baked = expected_metadata["vae_name"] == "Baked VAE"
            if not is_baked:
                actual_vae_hash = fields.get("VAE hash")
                actual_vae_hash_str = normalize_value(actual_vae_hash)
                if actual_vae_hash in (None, ""):
                    mark_fail("VAE hash", "computed hash", actual_vae_hash_str, "VAE hash missing")
                elif actual_vae_hash_str == "N/A":
                    mark_fail("VAE hash", "computed hash", actual_vae_hash_str, "VAE hash is 'N/A' - should be computed")
                else:
                    mark_pass("VAE hash", "hash present", actual_vae_hash_str)
            else:
                # For Baked VAE, hash should be N/A or missing
                actual_vae_hash = fields.get("VAE hash")
                if actual_vae_hash and normalize_value(actual_vae_hash) != "N/A":
                    mark_warn("VAE hash", "N/A", normalize_value(actual_vae_hash), "Baked VAE has unexpected hash value")
                else:
                    mark_pass("VAE hash", "N/A", "N/A")

        # Batch details, Flux parameters, CLIP/T5 prompts, etc.
        batch_size_expected = expected_metadata.get("batch_size")
        if batch_size_expected not in (None, 1, "1"):
            compare_numeric_field("Batch size", batch_size_expected)

        if expected_metadata.get("batch_number") is not None:
            compare_numeric_field("Batch number", expected_metadata["batch_number"])

        if expected_metadata.get("base_shift") is not None:
            compare_numeric_field("Base shift", expected_metadata["base_shift"])

        if expected_metadata.get("max_shift") is not None:
            compare_numeric_field("Max shift", expected_metadata["max_shift"])

        if expected_metadata.get("shift") is not None:
            compare_numeric_field("Shift", expected_metadata["shift"])

        if expected_metadata.get("weight_dtype"):
            compare_string_field("Weight dtype", expected_metadata["weight_dtype"])

        if expected_metadata.get("clip_prompt"):
            compare_string_field("CLIP Prompt", expected_metadata.get("clip_prompt"))

        if expected_metadata.get("t5_prompt"):
            compare_string_field("T5 Prompt", expected_metadata.get("t5_prompt"))

        if expected_metadata.get("clip_model_name"):
            compare_string_field("CLIP Model name", expected_metadata.get("clip_model_name"))

        if expected_metadata.get("embedding_name"):
            compare_string_field("Embedding name", expected_metadata.get("embedding_name"))

        # Store check count
        result["checks_performed"] = sum(1 for detail in check_details if detail["status"] in {"pass", "fail", "warn"})

    def validate_image(
        self,
        image_path: Path,
        workflow_name: str,
        expected: dict,
        expected_save_node: dict | None = None,
        verbose: bool = False,
    ) -> dict:
        """Validate a single image's metadata.

        Args:
            image_path: Path to the image file
            workflow_name: Name of the workflow
            expected: Overall expected metadata from workflow
            expected_save_node: Specific expected metadata for this save node (if known)
            verbose: If True, print detailed reverse validation info for each field
        """
        result = {
            "image_path": str(image_path),
            "workflow_name": workflow_name,
            "passed": False,
            "errors": [],
            "warnings": [],
            "notes": [],
            "metadata_found": False,
            "fields": {},
            "check_details": [],
        }

        # Check if this is a control image (without metadata)
        # Control images are saved using the default SaveImage node and are expected
        # to have no metadata or parameters field
        is_control_image = "without-meta" in image_path.name.lower()

        # Read metadata
        metadata = MetadataReader.read_metadata(image_path)

        # Handle control images: they should have no metadata or parameters
        if is_control_image:
            if not metadata or not metadata.get("parameters", ""):
                # Expected behavior for control images
                result["passed"] = True
                result["warnings"].append("Control image (without-meta) - no metadata expected")
                result["checks_performed"] = 0
                return result
            # Control image unexpectedly has metadata - continue with normal validation
            # but add a warning
            result["warnings"].append("Control image (without-meta) has unexpected metadata - validating anyway")

        # For non-control images, metadata is required
        if not metadata:
            result["errors"].append("No metadata found in image")
            return result

        result["metadata_found"] = True

        # Get parameters string
        params_str = metadata.get("parameters", "")
        if not params_str:
            result["errors"].append("No 'parameters' field found in metadata")
            return result

        # Parse parameters
        fields = self.parse_parameters_string(params_str)
        result["fields"] = fields

        # Comprehensive validation if we have detailed expected metadata
        if expected_save_node:
            self._validate_expected_fields(fields, expected_save_node, result)
        else:
            # Fallback to basic validation
            # Check for required fields based on workflow
            required_fields = []
            if expected.get("save_nodes"):
                # Use first save node
                save_node = expected["save_nodes"][0]
                if save_node.get("steps"):
                    required_fields.append("Steps")
                if save_node.get("sampler_name"):
                    required_fields.append("Sampler")
                if save_node.get("cfg"):
                    required_fields.append("CFG scale")
                if save_node.get("seed") is not None:
                    required_fields.append("Seed")

            # Validate required fields
            check_details = result.setdefault("check_details", [])
            for field in required_fields:
                actual_value = fields.get(field)
                if actual_value is None:
                    result["errors"].append(f"Required field '{field}' not found in metadata")
                    check_details.append(
                        {
                            "field": field,
                            "status": "fail",
                            "expected": "present",
                            "actual": "N/A",
                        }
                    )
                else:
                    check_details.append(
                        {
                            "field": field,
                            "status": "pass",
                            "expected": "present",
                            "actual": actual_value,
                        }
                    )

            if required_fields and "checks_performed" not in result:
                result["checks_performed"] = sum(1 for detail in check_details if detail.get("status") in {"pass", "fail", "warn"})

        # Check for fallback indicator
        if "Metadata Fallback:" in params_str:
            fallback_match = re.search(r"Metadata Fallback:\s*(\S+)", params_str)
            if fallback_match:
                fallback_stage = fallback_match.group(1)
                result["warnings"].append(f"Metadata fallback occurred: {fallback_stage}")
                result["fallback_stage"] = fallback_stage

        # Check for N/A values in any field (should never happen outside special cases)
        baked_vae = MetadataValidator._is_baked_vae(fields)
        for field_name, field_value in fields.items():
            if isinstance(field_value, str) and field_value.strip() == "N/A":
                if field_name == "VAE hash" and baked_vae:
                    continue
                result["errors"].append(f"Field '{field_name}' contains 'N/A' value: {field_value}")

        # Validate Hashes summary (required for parity checks)
        hashes_dict: dict[str, Any] | None = None
        if "Hashes" in fields:
            try:
                hashes_dict = json.loads(fields["Hashes"])
            except json.JSONDecodeError:
                result["errors"].append("Hashes field is not valid JSON")
        else:
            message = "Hashes summary missing from metadata"
            result["errors"].append(message)
            MetadataValidator._record_check_detail(result, "Hashes summary", "fail", "present", "missing", message)

        if hashes_dict is None:
            hashes_dict = {}
        self._validate_hashes_summary(fields, hashes_dict, result)

        # Validate hashes against sidecar files (if models path provided)
        self._validate_hashes_against_sidecars(fields, self.comfyui_models_path, result)

        # Validate embedding fields
        self._validate_embedding_fields(fields, result)

        # Ensure required parameter groupings exist
        self._validate_required_field_pairs(fields, result)

        # Ensure artifact hashes stay unique
        self._validate_hash_uniqueness(fields, result)

        # Validate file format matches expectation
        def normalize_format(fmt: Any) -> str | None:
            if fmt is None or fmt == "":
                return None
            fmt_str = str(fmt).lower()
            return "jpeg" if fmt_str == "jpg" else fmt_str

        expected_format = normalize_format((expected_save_node or {}).get("file_format"))
        if expected_format is None:
            expected_format = normalize_format(expected.get("file_format", "png")) or "png"

        actual_format = normalize_format(image_path.suffix.lower().lstrip(".")) or ""

        if expected_format != actual_format:
            result["warnings"].append(f"File format mismatch: expected {expected_format}, got {actual_format}")

        # Ensure the displayed check count matches every recorded validation detail
        result["checks_performed"] = sum(
            1
            for detail in result.get("check_details", [])
            if detail.get("status") in {"pass", "fail", "warn"}
        )

        # Perform reverse validation: verify each metadata field has a corresponding check
        if fields:
            if verbose:
                print(f"\n  Reverse validation for {image_path.name}:")
            reverse_stats = self._validate_reverse_coverage(fields, result, verbose=verbose)
            result["reverse_validation"] = reverse_stats

            # Add warnings for missing required field checks
            for missing_check in reverse_stats.get("missing_required_checks", []):
                result["warnings"].append(
                    f"Required field '{missing_check}' present but no validation check found"
                )

            if verbose:
                print(
                    f"  Reverse checks: {reverse_stats['validated_fields']}/{reverse_stats['total_fields']} "
                    f"({reverse_stats['coverage_percentage']:.1f}%)"
                )
                if reverse_stats["unvalidated_fields"]:
                    print(f"  Unvalidated fields: {', '.join(reverse_stats['unvalidated_fields'])}")

        # Mark as passed if no errors
        result["passed"] = len(result["errors"]) == 0

        return result

    def _validate_reverse_coverage(self, fields: dict, result: dict, verbose: bool = False) -> dict[str, Any]:
        """Reverse validation: verify each metadata field has a corresponding check.

        This method iterates through all fields found in the metadata and verifies
        that each field is being validated by the validation script. It provides
        coverage analysis to ensure no metadata fields are being silently ignored.

        Args:
            fields: Dictionary of parsed metadata fields from the image
            result: Validation result dict containing check_details
            verbose: If True, print detailed info about each field's coverage

        Returns:
            Dictionary containing reverse validation statistics:
            - total_fields: Number of fields found in metadata
            - validated_fields: Number of fields with corresponding checks
            - unvalidated_fields: List of field names without checks
            - coverage_percentage: Percentage of fields with checks
            - field_details: List of {field, has_check, check_source} dicts
        """
        check_details = result.get("check_details", [])

        # Build set of validated field names from check_details
        validated_field_names: set[str] = set()
        for detail in check_details:
            field_name = detail.get("field", "")
            if field_name:
                # Normalize field names: extract base field from compound names
                # e.g., "Hashes LoRA:model entry" -> track as validated for Lora_N fields
                validated_field_names.add(field_name)

        reverse_stats: dict[str, Any] = {
            "total_fields": 0,
            "validated_fields": 0,
            "unvalidated_fields": [],
            "coverage_percentage": 0.0,
            "field_details": [],
            "missing_required_checks": [],
        }

        # Track which fields we've seen
        field_details: list[dict[str, Any]] = []

        for field_name, field_value in fields.items():
            # Skip empty fields
            if field_value is None or (isinstance(field_value, str) and not field_value.strip()):
                continue

            reverse_stats["total_fields"] += 1

            # Determine if this field has a corresponding validation check
            has_check = False
            check_source = "none"

            # Check 1: Direct field match in check_details (field was actually validated)
            if field_name in validated_field_names:
                has_check = True
                check_source = "direct"

            # Check 2: Extra metadata fields are recorded as "Extra: {field}" in check_details
            if not has_check:
                extra_field_name = f"Extra: {field_name}"
                if extra_field_name in validated_field_names:
                    has_check = True
                    check_source = "extra_metadata"

            # Check 3: Hashes summary field is validated by any Hashes-related check
            if not has_check and field_name == "Hashes":
                has_check = any("Hashes" in detail.get("field", "") for detail in check_details)
                if has_check:
                    check_source = "hashes_summary"

            # Check 4: Informational fields that genuinely don't need validation
            # These are summary/display fields that are not testable against expected values
            if not has_check and field_name in self.INFORMATIONAL_FIELDS:
                has_check = True
                check_source = "informational"

            # Check 5: Metadata generator version is always present and validated implicitly
            if not has_check and field_name == "Metadata generator version":
                has_check = True
                check_source = "always_validated"

            # Record result
            if has_check:
                reverse_stats["validated_fields"] += 1
            else:
                reverse_stats["unvalidated_fields"].append(field_name)

            field_details.append({
                "field": field_name,
                "has_check": has_check,
                "check_source": check_source,
                "value_preview": str(field_value)[:50] + ("..." if len(str(field_value)) > 50 else ""),
            })

            if verbose:
                status = "✓" if has_check else "✗"
                source_info = f" ({check_source})" if has_check else ""
                print(f"  {status} {field_name}: {source_info}")

        reverse_stats["field_details"] = field_details

        # Calculate coverage percentage
        if reverse_stats["total_fields"] > 0:
            reverse_stats["coverage_percentage"] = (
                reverse_stats["validated_fields"] / reverse_stats["total_fields"] * 100
            )

        # Self-validate: Check that required core fields have checks when present
        for required_field in self.REQUIRED_CORE_FIELDS:
            if required_field in fields:
                field_validated = any(
                    detail.get("field") == required_field and detail.get("status") in {"pass", "fail", "warn"}
                    for detail in check_details
                )
                if not field_validated:
                    reverse_stats["missing_required_checks"].append(required_field)

        # Check CFG/Guidance requirement
        cfg_or_guidance_present = any(f in fields for f in self.REQUIRED_CFG_OR_GUIDANCE)
        if cfg_or_guidance_present:
            cfg_guidance_validated = any(
                detail.get("field") in self.REQUIRED_CFG_OR_GUIDANCE
                and detail.get("status") in {"pass", "fail", "warn"}
                for detail in check_details
            )
            if not cfg_guidance_validated:
                reverse_stats["missing_required_checks"].append("CFG scale/Guidance")

        return reverse_stats

    def _validate_hashes_summary(self, fields: dict, hashes_dict: dict, result: dict):
        """Validate that the Hashes summary matches the metadata entries."""

        def record(field: str, status: str, expected_val: Any | None, actual_val: Any | None, message: str | None = None) -> None:
            MetadataValidator._record_check_detail(result, field, status, expected_val, actual_val, message)

        def record_presence(field_label: str, present: bool, message: str) -> None:
            if present:
                record(field_label, "pass", "present", "present")
            else:
                result["errors"].append(message)
                record(field_label, "fail", "present", "missing", message)

        def record_hash_match(field_label: str, expected_hash: str | None, actual_hash: str | None, missing_msg: str) -> None:
            if actual_hash in (None, ""):
                result["errors"].append(missing_msg)
                record(field_label, "fail", expected_hash or "hash", "missing", missing_msg)
                return
            if actual_hash == "N/A":
                result["errors"].append(missing_msg)
                record(field_label, "fail", expected_hash or "hash", "N/A", missing_msg)
                return
            if expected_hash is None:
                record(field_label, "warn", "hash", actual_hash, "Hashes summary missing reference value")
                return
            if expected_hash.lower() != actual_hash.lower():
                message = f"Hash mismatch: expected '{expected_hash}' but found '{actual_hash}'"
                result["errors"].append(message)
                record(field_label, "fail", expected_hash, actual_hash, message)
            else:
                record(field_label, "pass", expected_hash, actual_hash)

        # LoRAs
        lora_indices = sorted(
            {
                int(match.group(1))
                for key in fields.keys()
                for match in [re.match(r"Lora_(\d+) Model name", key)]
                if match
            }
        )

        for idx in lora_indices:
            model_name_key = f"Lora_{idx} Model name"
            model_hash_key = f"Lora_{idx} Model hash"
            model_name = fields.get(model_name_key)
            if not model_name:
                continue

            model_name_base = model_name.replace(".safetensors", "").replace(".pt", "").replace(".ckpt", "")
            lora_key = f"lora:{model_name_base}"

            presence_label = f"Hashes LoRA:{model_name_base} entry"
            record_presence(presence_label, lora_key in hashes_dict, f"LoRA '{model_name}' missing from Hashes summary")

            if lora_key in hashes_dict and model_hash_key in fields:
                match_label = f"Hashes LoRA:{model_name_base} match"
                record_hash_match(
                    match_label,
                    hashes_dict[lora_key],
                    fields.get(model_hash_key),
                    f"LoRA '{model_name}' hash missing in parameters",
                )

            if model_hash_key in fields and fields[model_hash_key] == "N/A":
                message = f"LoRA hash for Lora_{idx} is 'N/A' - hash should always be computed"
                result["errors"].append(message)
                record(f"Lora_{idx} Model hash", "fail", "hash present", "N/A", message)

        # Embeddings
        embedding_indices = sorted(
            {
                int(match.group(1))
                for key in fields.keys()
                for match in [re.match(r"Embedding_(\d+) name", key)]
                if match
            }
        )

        for idx in embedding_indices:
            name_key = f"Embedding_{idx} name"
            hash_key = f"Embedding_{idx} hash"
            emb_name = fields.get(name_key)
            if not emb_name:
                continue

            hashes_key = f"embed:{emb_name}"
            alt_key = None
            for key in hashes_dict.keys():
                if not key.startswith("embed:"):
                    continue
                embed_name_in_hash = key.replace("embed:", "")
                if embed_name_in_hash == emb_name:
                    hashes_key = key
                    break
                if embed_name_in_hash.isdigit() and alt_key is None:
                    alt_key = key

            presence_label = f"Hashes Embedding:{emb_name} entry"
            if hashes_key in hashes_dict:
                record_presence(presence_label, True, "")
            elif alt_key:
                message = (
                    f"Embedding_{idx} '{emb_name}' recorded under wrong key '{alt_key}' instead of 'embed:{emb_name}'"
                )
                result["errors"].append(message)
                record(presence_label, "fail", f"embed:{emb_name}", alt_key, message)
            else:
                record_presence(presence_label, False, f"Embedding_{idx} '{emb_name}' missing from Hashes summary")

            if hashes_key in hashes_dict and hash_key in fields:
                match_label = f"Hashes Embedding:{emb_name} match"
                record_hash_match(
                    match_label,
                    hashes_dict[hashes_key],
                    fields.get(hash_key),
                    f"Embedding_{idx} hash missing in parameters",
                )

            if hash_key in fields and fields[hash_key] == "N/A":
                message = f"Embedding hash for Embedding_{idx} is 'N/A' - hash should always be computed"
                result["errors"].append(message)
                record(f"Embedding_{idx} hash", "fail", "hash present", "N/A", message)

        # Model
        if "Model" in fields or "Model hash" in fields:
            presence_label = "Hashes Model entry"
            record_presence(presence_label, "model" in hashes_dict, "Model missing from Hashes summary")
            if "model" in hashes_dict and "Model hash" in fields:
                record_hash_match(
                    "Hashes Model match",
                    hashes_dict.get("model"),
                    fields.get("Model hash"),
                    "Model hash missing in parameters",
                )

        # VAE
        if "VAE" in fields and not MetadataValidator._is_baked_vae(fields):
            presence_label = "Hashes VAE entry"
            record_presence(presence_label, "vae" in hashes_dict, "VAE missing from Hashes summary")
            if "vae" in hashes_dict and "VAE hash" in fields:
                record_hash_match(
                    "Hashes VAE match",
                    hashes_dict.get("vae"),
                    fields.get("VAE hash"),
                    "VAE hash missing in parameters",
                )

    def _validate_hash_against_sidecar(
        self, artifact_name: str, metadata_hash: str, artifact_type: str, comfyui_models_path: Path | None, result: dict
    ):
        """Validate hash from metadata against .sha256 sidecar file.

        Args:
            artifact_name: Name of the model/lora/vae/embedding file
            metadata_hash: Hash from the metadata (should be 10 chars)
            artifact_type: Type of artifact ("model", "lora", "vae", "embedding")
            comfyui_models_path: Path to ComfyUI models directory (optional)
            result: Result dict to append errors to
        """
        if not comfyui_models_path or not comfyui_models_path.exists():
            # Silently skip if models path not available
            return

        field_label = f"Sidecar {artifact_type}:{artifact_name}"

        # Validate metadata hash is 10 characters
        if len(metadata_hash) != 10:
            message = f"{artifact_type.title()} '{artifact_name}' hash in metadata is not 10 characters: '{metadata_hash}'"
            result["errors"].append(message)
            MetadataValidator._record_check_detail(result, field_label, "fail", "10 chars", metadata_hash, message)
            return

        # Try to find the artifact file
        # Common subdirectories for different artifact types
        # Based on user's ComfyUI setup:
        # unet/diffusion models: "diffusion_models", "DiffusionModels", "unet", "StableDiffusion"
        # embeddings: "Embeddings"
        # loras: "Lora"
        # ckpt: "StableDiffusion"
        # vae: "VAE"
        search_dirs = {
            "model": ["diffusion_models", "DiffusionModels", "unet", "StableDiffusion", "checkpoints"],
            "lora": ["Lora", "loras"],
            "vae": ["VAE", "vae"],
            "embedding": ["Embeddings", "embeddings"],
        }

        artifact_path = None
        for subdir in search_dirs.get(artifact_type, []):
            search_path = comfyui_models_path / subdir
            if search_path.exists():
                # Search recursively for the artifact
                for candidate in search_path.rglob(artifact_name):
                    if candidate.is_file():
                        artifact_path = candidate
                        break
                if artifact_path:
                    break

        if not artifact_path:
            # Artifact not found - log detailed search info for troubleshooting
            searched_dirs = [str(comfyui_models_path / subdir) for subdir in search_dirs.get(artifact_type, [])]
            message = f"Hash validation: {artifact_type.title()} '{artifact_name}' not found. Searched in: {', '.join(searched_dirs)}"
            if self.verbose:
                result["warnings"].append(message)
            MetadataValidator._record_check_detail(result, field_label, "warn", "artifact present", "missing", message)
            return

        # Check for sidecar file (prefer extension-less sidecar)
        sidecar_candidates = [
            artifact_path.with_suffix(".sha256"),
            artifact_path.with_suffix(artifact_path.suffix + ".sha256"),
        ]

        sidecar_path = None
        for candidate in sidecar_candidates:
            if candidate.exists():
                sidecar_path = candidate
                break

        if not sidecar_path:
            attempted = ", ".join(str(candidate) for candidate in sidecar_candidates)
            message = f"Hash validation: {artifact_type.title()} '{artifact_name}' has no .sha256 sidecar file (checked: {attempted})"
            result["warnings"].append(message)
            MetadataValidator._record_check_detail(result, field_label, "warn", "sidecar", "missing", message)
            return

        # Read sidecar file
        try:
            with open(sidecar_path, encoding="utf-8") as f:
                sidecar_hash = f.read().strip()

            # Validate sidecar hash is 64 characters
            if len(sidecar_hash) != 64:
                message = (
                    f"Hash validation FAILED: {artifact_type.title()} '{artifact_name}' sidecar hash is not 64 characters: '{sidecar_hash}'"
                )
                result["errors"].append(message)
                MetadataValidator._record_check_detail(result, field_label, "fail", "64 chars", len(sidecar_hash), message)
                return

            # Validate sidecar hash is hex
            if not all(c in "0123456789abcdefABCDEF" for c in sidecar_hash):
                message = (
                    f"Hash validation FAILED: {artifact_type.title()} '{artifact_name}' sidecar hash is not valid hex: '{sidecar_hash}'"
                )
                result["errors"].append(message)
                MetadataValidator._record_check_detail(result, field_label, "fail", "hex", sidecar_hash, message)
                return

            # Validate metadata hash matches first 10 characters of sidecar hash
            if metadata_hash.lower() != sidecar_hash[:10].lower():
                message = (
                    f"Hash validation FAILED: {artifact_type.title()} '{artifact_name}' hash mismatch: "
                    f"metadata has '{metadata_hash}' but sidecar first 10 chars are '{sidecar_hash[:10]}'"
                )
                result["errors"].append(message)
                MetadataValidator._record_check_detail(result, field_label, "fail", sidecar_hash[:10], metadata_hash, message)
            else:
                # Hash validation passed - log in verbose mode
                message = (
                    f"Hash validation PASSED: {artifact_type.title()} '{artifact_name}' "
                    f"(metadata: {metadata_hash}, sidecar: {sidecar_hash[:10]}... [64 chars total])"
                )
                if self.verbose:
                    result.setdefault("notes", []).append(message)
                MetadataValidator._record_check_detail(result, field_label, "pass", sidecar_hash[:10], metadata_hash)

        except Exception as e:
            message = f"Hash validation ERROR: Failed to read sidecar file for '{artifact_name}': {e}"
            result["warnings"].append(message)
            MetadataValidator._record_check_detail(result, field_label, "warn", "readable sidecar", "error", message)

    def _validate_hashes_against_sidecars(self, fields: dict, comfyui_models_path: Path | None, result: dict):
        """Validate all hashes in metadata against their .sha256 sidecar files."""
        if not comfyui_models_path:
            return

        # Validate model hash
        if "Model" in fields and "Model hash" in fields:
            self._validate_hash_against_sidecar(fields["Model"], fields["Model hash"], "model", comfyui_models_path, result)

        # Validate VAE hash
        if "VAE" in fields and "VAE hash" in fields:
            if fields["VAE hash"] != "N/A" and not MetadataValidator._is_baked_vae(fields):
                self._validate_hash_against_sidecar(fields["VAE"], fields["VAE hash"], "vae", comfyui_models_path, result)

        # Validate LoRA hashes
        lora_indices = set()
        for key in fields.keys():
            if key.startswith("Lora_") and "Model name" in key:
                match = re.match(r"Lora_(\d+) Model name", key)
                if match:
                    lora_indices.add(int(match.group(1)))

        for idx in lora_indices:
            model_name_key = f"Lora_{idx} Model name"
            model_hash_key = f"Lora_{idx} Model hash"
            if model_name_key in fields and model_hash_key in fields:
                if fields[model_hash_key] != "N/A":
                    self._validate_hash_against_sidecar(fields[model_name_key], fields[model_hash_key], "lora", comfyui_models_path, result)

        # Validate embedding hashes
        embedding_indices = set()
        for key in fields.keys():
            if key.startswith("Embedding_") and "hash" in key:
                match = re.match(r"Embedding_(\d+) hash", key)
                if match:
                    embedding_indices.add(int(match.group(1)))

        for idx in embedding_indices:
            name_key = f"Embedding_{idx} name"
            hash_key = f"Embedding_{idx} hash"
            if name_key in fields and hash_key in fields:
                self._validate_hash_against_sidecar(fields[name_key], fields[hash_key], "embedding", comfyui_models_path, result)

    def _validate_embedding_fields(self, fields: dict, result: dict):
        """Validate embedding-specific issues."""
        for key, value in fields.items():
            if "Embedding_" in key and "name" in key:
                # Check for trailing punctuation (commas, periods, semicolons, colons)
                if value.rstrip(",.;:") != value:
                    message = f"Embedding name '{key}' has trailing punctuation: '{value}'"
                    result["errors"].append(message)
                    MetadataValidator._record_check_detail(result, key, "fail", "trimmed", value, message)

                # Check if this is actually a prompt (very long text suggests it's not an embedding)
                if len(value) > 100:
                    message = f"Embedding name '{key}' appears to be a prompt (length={len(value)}), not an embedding name"
                    result["errors"].append(message)
                    MetadataValidator._record_check_detail(result, key, "fail", "short name", f"len={len(value)}", message)

            # Check if embedding hash is also suspiciously long (suggests it's a prompt)
            # Normal hashes are typically 10-64 characters (sha256 truncated or full)
            if "Embedding_" in key and "hash" in key:
                if len(value) > 70:
                    message = f"Embedding hash '{key}' appears to be a prompt (length={len(value)}), not a hash"
                    result["errors"].append(message)
                    MetadataValidator._record_check_detail(result, key, "fail", "<=64 chars", f"len={len(value)}", message)

    def _validate_required_field_pairs(self, fields: dict, result: dict) -> None:
        """Ensure each metadata grouping includes its required companion fields."""

        def has_value(value: Any) -> bool:
            if value is None:
                return False
            if isinstance(value, str):
                stripped = value.strip()
                return stripped not in {"", "N/A"}
            return True

        def record_presence(field_label: str, key: str, *, allow_na: bool = False) -> None:
            value = fields.get(key)
            if value is None or (isinstance(value, str) and value.strip() == ""):
                message = f"{field_label} missing from metadata"
                result["errors"].append(message)
                MetadataValidator._record_check_detail(result, field_label, "fail", "present", "missing", message)
                return
            if isinstance(value, str) and value.strip() == "N/A" and not allow_na:
                message = f"{field_label} is 'N/A' but should be recorded"
                result["errors"].append(message)
                MetadataValidator._record_check_detail(result, field_label, "fail", "present", "N/A", message)
                return
            MetadataValidator._record_check_detail(result, field_label, "pass", "present", value)

        def record_relationship(label: str, primary_key: str, related_key: str) -> None:
            primary_val = fields.get(primary_key)
            if not has_value(primary_val):
                return
            related_val = fields.get(related_key)
            if not has_value(related_val):
                message = f"{label} missing counterpart field '{related_key}'"
                result["errors"].append(message)
                MetadataValidator._record_check_detail(result, label, "fail", "present", "missing", message)
            else:
                MetadataValidator._record_check_detail(result, label, "pass", "present", "present")

        if "Model" in fields:
            record_presence("Model field", "Model")
            record_presence("Model hash field", "Model hash")

        if "VAE" in fields and not MetadataValidator._is_baked_vae(fields):
            record_presence("VAE field", "VAE")
            record_presence("VAE hash field", "VAE hash")

        lora_indices = sorted(
            {
                int(match.group(1))
                for key in fields.keys()
                for match in [re.match(r"Lora_(\d+)", key)]
                if match
            }
        )
        for idx in lora_indices:
            name_key = f"Lora_{idx} Model name"
            hash_key = f"Lora_{idx} Model hash"
            strength_key = f"Lora_{idx} Strength model"
            record_presence(f"{name_key} present", name_key)
            record_presence(f"{hash_key} present", hash_key)
            record_presence(f"{strength_key} present", strength_key)

            record_relationship(f"{name_key} linked hash", name_key, hash_key)
            record_relationship(f"{name_key} linked strength", name_key, strength_key)
            record_relationship(f"{hash_key} linked model", hash_key, name_key)
            record_relationship(f"{hash_key} linked strength", hash_key, strength_key)
            record_relationship(f"{strength_key} linked model", strength_key, name_key)
            record_relationship(f"{strength_key} linked hash", strength_key, hash_key)

        embedding_indices = sorted(
            {
                int(match.group(1))
                for key in fields.keys()
                for match in [re.match(r"Embedding_(\d+)", key)]
                if match
            }
        )
        for idx in embedding_indices:
            name_key = f"Embedding_{idx} name"
            hash_key = f"Embedding_{idx} hash"
            record_presence(f"{name_key} present", name_key)
            record_presence(f"{hash_key} present", hash_key)

    def _validate_hash_uniqueness(self, fields: dict, result: dict) -> None:
        """Ensure artifact hashes are unique across all recorded items."""

        def add_hash(label: str, value: Any, collector: list[tuple[str, str]]) -> None:
            if value in (None, "", "N/A"):
                return
            collector.append((label, str(value).strip()))

        artifact_hashes: list[tuple[str, str]] = []
        add_hash("Model", fields.get("Model hash"), artifact_hashes)

        if not MetadataValidator._is_baked_vae(fields):
            add_hash("VAE", fields.get("VAE hash"), artifact_hashes)

        lora_indices = sorted(
            {
                int(match.group(1))
                for key in fields.keys()
                for match in [re.match(r"Lora_(\d+) Model hash", key)]
                if match
            }
        )
        for idx in lora_indices:
            add_hash(f"LoRA {idx}", fields.get(f"Lora_{idx} Model hash"), artifact_hashes)

        embedding_indices = sorted(
            {
                int(match.group(1))
                for key in fields.keys()
                for match in [re.match(r"Embedding_(\d+) hash", key)]
                if match
            }
        )
        for idx in embedding_indices:
            add_hash(f"Embedding {idx}", fields.get(f"Embedding_{idx} hash"), artifact_hashes)

        seen: dict[str, str] = {}
        duplicates: dict[str, set[str]] = {}
        for label, value in artifact_hashes:
            token = value.lower()
            if token in seen and seen[token] != label:
                duplicates.setdefault(token, {seen[token]}).add(label)
            else:
                seen[token] = label

        if duplicates:
            parts = [f"{', '.join(sorted(labels))} -> {hash_value}" for hash_value, labels in duplicates.items()]
            message = "Duplicate artifact hashes detected: " + "; ".join(parts)
            result["errors"].append(message)
            MetadataValidator._record_check_detail(result, "Hash uniqueness", "fail", "unique", message)
        elif artifact_hashes:
            MetadataValidator._record_check_detail(
                result,
                "Hash uniqueness",
                "pass",
                "unique",
                f"{len(artifact_hashes)} unique hashes",
            )

    def _score_image_for_workflow(
        self,
        image_path: Path,
        filename_patterns: list[str] | None,
        expected: dict[str, Any] | None,
    ) -> int:
        """Return a relative score indicating how well an image matches a workflow."""

        if expected is None and not filename_patterns:
            return 0

        image_name = image_path.stem.lower()
        patterns = filename_patterns or []
        if expected and not patterns:
            patterns = expected.get("filename_patterns", []) or []

        best_score = 0

        if expected:
            for marker in expected.get("filename_leaf_markers", []) or []:
                marker_lower = marker.lower()
                if marker_lower and image_name.startswith(marker_lower):
                    best_score = max(best_score, 200 + len(marker_lower))

        for pattern in patterns:
            pattern_lower = pattern.lower()
            if not pattern_lower:
                continue
            regex = r"(^|[_\-.])" + re.escape(pattern_lower) + r"($|[_\-.])"
            if re.search(regex, image_name):
                best_score = max(best_score, 100 + len(pattern_lower))

        if best_score == 0 and expected and expected.get("filename_prefix"):
            prefix = expected["filename_prefix"]
            if any(sep in prefix for sep in ("/", "\\")):
                try:
                    rel_path = image_path.relative_to(self.output_dir)
                    if len(rel_path.parts) > 1:
                        best_score = max(best_score, 25)
                except ValueError:
                    # image_path is not relative to self.output_dir; ignore and continue
                    pass

        return best_score

    def match_image_to_workflow(self, image_path: Path, filename_patterns: list[str], expected: dict[str, Any] | None = None) -> bool:
        """Check if an image filename matches any of the workflow's filename patterns.

        Uses word-boundary matching to avoid false positives like "eff" matching "jeff_image.png".
        Patterns must match as whole words or be separated by delimiters (_, -, .).

        If no static patterns exist, falls back to checking if the image is in a subdirectory
        structure that matches the workflow's filename_prefix path pattern, or matches based
        on seed values if available.
        """
        return self._score_image_for_workflow(image_path, filename_patterns, expected) > 0

    @staticmethod
    def _select_save_node_for_image(image_name_lower: str, save_nodes: list[dict[str, Any]] | None) -> dict | None:
        if not save_nodes:
            return None

        # Prefer direct matches against the sanitized filename_prefix leaf stored per save node
        for node in save_nodes:
            marker = str(node.get("filename_prefix_leaf") or "").lower()
            if marker and image_name_lower.startswith(marker):
                return node

        # Fallback to legacy pattern matching semantics if no leaf markers matched
        for node in save_nodes:
            patterns = node.get("filename_patterns", []) or []
            for pattern in patterns:
                pattern_lower = pattern.lower()
                if not pattern_lower:
                    continue
                regex = r"(^|[_\-.])" + re.escape(pattern_lower) + r"($|[_\-.])"
                if re.search(regex, image_name_lower):
                    return node

        # Final fallback: return first save node if nothing matched explicitly
        return save_nodes[0]

    def _print_validation_result(self, result: dict, save_node_metadata: dict | None = None):
        """Print validation result with optional verbose output."""
        status = "✓" if result["passed"] else "✗"
        checks = result.get("checks_performed", 0)
        image_path = Path(result["image_path"])
        print(f"    {status} {image_path.name} ({checks} checks)")

        # Print errors
        for error in result["errors"]:
            print(f"        Error: {error}")

        # Print warnings
        for warning in result["warnings"]:
            print(f"        Warning: {warning}")

        # Print informational notes (e.g., hash validation successes)
        if self.verbose:
            for note in result.get("notes", []):
                print(f"        Info: {note}")

        # In non-verbose mode, show key fields for passed validations
        if not self.verbose and result["passed"] and result.get("fields"):
            fields = result["fields"]
            if "Steps" in fields:
                print(f"        Steps: {fields['Steps']}")
            if "Sampler" in fields:
                print(f"        Sampler: {fields['Sampler']}")
            if "Seed" in fields:
                print(f"        Seed: {fields['Seed']}")

        # In verbose mode, show captured check details
        if self.verbose and result.get("metadata_found"):
            check_details = result.get("check_details", [])
            if check_details:
                print("        Validation Details:")
                for detail in check_details:
                    status = detail.get("status", "info")
                    symbol_map = {"pass": "✓", "fail": "✗", "warn": "⚠", "info": "ℹ"}
                    symbol = symbol_map.get(status, "ℹ")
                    field_name = detail.get("field", "Field")
                    expected = detail.get("expected")
                    actual = detail.get("actual", "N/A")
                    if expected is not None and status != "info":
                        print(f"          {symbol} {field_name}: expected={expected}, actual={actual}")
                    else:
                        print(f"          {symbol} {field_name}: {actual}")

    def validate_workflow_outputs(
        self,
        workflow_file: Path,
        all_images: list[Path],
        *,
        workflow_data: dict | None = None,
        expected_metadata: dict[str, Any] | None = None,
        prefiltered_images: list[Path] | None = None,
    ) -> list[dict]:
        """Validate images generated by a specific workflow."""
        print(f"\nValidating workflow: {workflow_file.name}")

        # Special case: 1-scan-and-save-custom-metadata-rules.json doesn't create images
        # It only contains Metadata Rule Scanner + Save Custom Metadata Rules nodes
        if workflow_file.name == "1-scan-and-save-custom-metadata-rules.json":
            print("  ℹ Info: This workflow generates metadata rules, not images (skipping)")
            return []

        workflow = workflow_data
        if workflow is None:
            try:
                with open(workflow_file, encoding="utf-8") as f:
                    workflow = json.load(f)
            except Exception as e:
                print(f"  ✗ Error loading workflow: {e}")
                return []

        # Extract expected metadata (now includes detailed save node info)
        expected = expected_metadata or WorkflowAnalyzer.extract_expected_metadata(workflow, workflow_file.stem)

        if not expected["has_save_node"]:
            print("  ⚠ Warning: No Save Image node found in workflow")
            return []

        # Show summary
        num_save_nodes = len(expected.get("save_nodes", []))
        print(f"  Found {num_save_nodes} Save Image node(s)")

        # Show the filename patterns we're looking for
        patterns = expected.get("filename_patterns", [])
        if patterns:
            print(f"  Filename patterns: {', '.join(patterns)}")

        # Filter images that match this workflow
        if prefiltered_images is not None:
            matching_images = prefiltered_images
        else:
            matching_images = []
            for image_path in all_images:
                if self.match_image_to_workflow(image_path, patterns, expected):
                    matching_images.append(image_path)

        if not matching_images:
            print("  ⚠ Warning: No matching images found for this workflow")
            return []

        print(f"  Found {len(matching_images)} matching image(s)")

        # Validate each matching image
        results = []
        for image_path in matching_images:
            # Try to match image to specific save node based on filename patterns
            best_save_node_match = None
            if expected.get("save_nodes"):
                best_save_node_match = self._select_save_node_for_image(
                    image_path.stem.lower(),
                    expected["save_nodes"],
                )

            # Validate with the matched save node's expected metadata
            result = self.validate_image(
                image_path,
                workflow_file.stem,
                expected,
                best_save_node_match,
                verbose=getattr(self, "verbose", False),
            )
            results.append(result)

            # Print result (with verbose option support)
            self._print_validation_result(result, best_save_node_match)

        return results

    def run_validation(self, extra_workflows_dir: Path | None = None) -> tuple[int, int, int]:
        """Run validation on all workflows and return (total, passed, failed).

        Args:
            extra_workflows_dir: Optional additional directory containing workflow JSON files
        """
        print("=" * 70)
        print("ComfyUI Metadata Validation")
        print("=" * 70)
        print(f"Workflow Dir: {self.workflow_dir}")
        if extra_workflows_dir:
            print(f"Extra Workflows: {extra_workflows_dir}")
        print(f"Output Dir:   {self.output_dir}")
        print("=" * 70)

        if not self.workflow_dir.exists():
            print(f"✗ Error: Workflow directory not found: {self.workflow_dir}")
            return 0, 0, 0

        if not self.output_dir.exists():
            print(f"✗ Error: Output directory not found: {self.output_dir}")
            return 0, 0, 0

        if not self.comfyui_models_path:
            print("⚠ Hash validation disabled: pass --models-path to enable sidecar checks")

        # Find all workflow files from both directories
        workflow_files = sorted(self.workflow_dir.glob("*.json"))

        if extra_workflows_dir:
            if extra_workflows_dir.exists():
                extra_workflow_files = sorted(extra_workflows_dir.glob("*.json"))
                workflow_files.extend(extra_workflow_files)
                print(f"Added {len(extra_workflow_files)} workflow(s) from extra directory")
            else:
                print(f"⚠ Warning: Extra workflows directory not found: {extra_workflows_dir}")

        if not workflow_files:
            print(f"⚠ No workflow files found in {self.workflow_dir}")
            return 0, 0, 0

        # Collect all images once (more efficient than searching for each workflow)
        print("\nScanning for images...")
        image_suffixes = {".png", ".jpg", ".jpeg", ".webp"}
        all_images = [f for f in self.output_dir.rglob("*") if f.is_file() and f.suffix.lower() in image_suffixes]
        print(f"Found {len(all_images)} total image(s) in output directory")

        if not all_images:
            print(f"⚠ Warning: No images found in {self.output_dir}")
            return 0, 0, 0

        # Preload workflow metadata for deterministic image assignment
        workflow_entries: list[dict[str, Any]] = []
        for workflow_file in workflow_files:
            try:
                with open(workflow_file, encoding="utf-8") as f:
                    workflow = json.load(f)
            except Exception as e:
                print(f"  ✗ Error loading workflow '{workflow_file.name}': {e}")
                continue

            expected = WorkflowAnalyzer.extract_expected_metadata(workflow, workflow_file.stem)
            workflow_entries.append({
                "file": workflow_file,
                "workflow": workflow,
                "expected": expected,
            })

        if not workflow_entries:
            print("⚠ No workflows could be loaded for validation")
            return 0, 0, 0

        workflow_to_images: dict[Path, list[Path]] = {entry["file"]: [] for entry in workflow_entries}
        for image_path in all_images:
            best_entry = None
            best_score = 0
            for entry in workflow_entries:
                expected = entry["expected"]
                if not expected.get("has_save_node"):
                    continue
                score = self._score_image_for_workflow(image_path, expected.get("filename_patterns"), expected)
                if score > best_score:
                    best_score = score
                    best_entry = entry

            if best_entry and best_score > 0:
                workflow_to_images[best_entry["file"]].append(image_path)

        initially_assigned = {img for images in workflow_to_images.values() for img in images}
        unassigned_images = set(all_images) - initially_assigned

        # Validate each workflow's outputs
        all_results = []
        validated_images = set()
        workflows_with_images = set()
        workflows_without_images = set()

        for entry in workflow_entries:
            workflow_file = entry["file"]
            assigned_images = workflow_to_images.get(workflow_file) or None
            search_pool = assigned_images or list(unassigned_images)
            results = self.validate_workflow_outputs(
                workflow_file,
                search_pool,
                workflow_data=entry["workflow"],
                expected_metadata=entry["expected"],
                prefiltered_images=assigned_images,
            )

            # Track workflows that had matching images vs those that didn't
            if results:
                workflows_with_images.add(workflow_file.name)
                all_results.extend(results)

                # Track which images were validated
                for result in results:
                    image_path = Path(result["image_path"])
                    validated_images.add(image_path)
                    if image_path in unassigned_images:
                        unassigned_images.remove(image_path)
            else:
                if workflow_file.name != "1-scan-and-save-custom-metadata-rules.json" and entry["expected"].get("has_save_node"):
                    workflows_without_images.add(workflow_file.name)

        # Calculate statistics
        total = len(all_results)
        passed = sum(1 for r in all_results if r["passed"])
        failed = total - passed
        unmatched_images = set(all_images) - validated_images

        # Build summary results list (excluding control images)
        summary_results = [
            result
            for result in all_results
            if "without-meta" not in Path(result["image_path"]).name.lower()
        ]

        # Print Checks Per Image BEFORE Validation Summary
        print("\n" + "=" * 70)
        print("Checks Per Image:")
        if summary_results:
            for result in summary_results:
                symbol = "✓" if result["passed"] else "✗"
                checks = result.get("checks_performed", 0)

                # Add reverse validation summary to each image line
                reverse_stats = result.get("reverse_validation", {})
                if reverse_stats:
                    reverse_total = reverse_stats.get("total_fields", 0)
                    reverse_passed = reverse_stats.get("validated_fields", 0)
                    reverse_failed = reverse_total - reverse_passed
                    reverse_info = f", reverse: {reverse_passed}/{reverse_total}"
                    if reverse_failed > 0:
                        reverse_info += f" ({reverse_failed} failed)"
                else:
                    reverse_info = ""

                print(f"  {symbol} {Path(result['image_path']).name} ({checks} checks{reverse_info})")
        else:
            print("  (control images with 'without-meta' prefix skipped)")

        # Print Validation Summary
        print("=" * 70)
        print("Validation Summary:")
        print(f"  Total Images Validated: {total}")
        print(f"  ✓ Passed:               {passed}")
        print(f"  ✗ Failed:               {failed}")
        print(f"  ⚠ Unmatched Images:     {len(unmatched_images)}")
        print(f"  ⚠ Unmatched Workflows:  {len(workflows_without_images)}")
        print("=" * 70)

        # Report unmatched images
        if unmatched_images:
            print(f"\nUnmatched Images ({len(unmatched_images)}):")
            for img in sorted(unmatched_images):
                print(f"  - {img.name}")

        # Report unmatched workflows
        if workflows_without_images:
            print(f"\nUnmatched Workflows ({len(workflows_without_images)}):")
            for wf in sorted(workflows_without_images):
                print(f"  - {wf}")

        # Report failed images
        if failed > 0:
            print(f"\nFailed Images ({failed}):")
            for result in all_results:
                if not result["passed"]:
                    print(f"  - {Path(result['image_path']).name} (workflow: {result['workflow_name']})")
                    for error in result["errors"]:
                        print(f"      {error}")

        # Collect and report reverse validation failures
        reverse_failures: list[tuple[str, list[dict]]] = []
        for result in all_results:
            if "without-meta" in Path(result["image_path"]).name.lower():
                continue
            reverse_stats = result.get("reverse_validation", {})
            if reverse_stats:
                failed_details = [
                    detail
                    for detail in reverse_stats.get("field_details", [])
                    if not detail.get("has_check")
                ]
                if failed_details:
                    reverse_failures.append((Path(result["image_path"]).name, failed_details))

        if reverse_failures:
            print(f"\nFailed Reverse Validation Checks ({len(reverse_failures)}):")
            for image_name, failed_details in reverse_failures:
                print(f"  - {image_name}")
                for detail in failed_details:
                    print(f"      ✗ {detail['field']}")

        # Collect and report missing required field checks per image
        missing_required_by_image: list[tuple[str, list[str]]] = []
        for result in all_results:
            if "without-meta" in Path(result["image_path"]).name.lower():
                continue
            reverse_stats = result.get("reverse_validation", {})
            if reverse_stats:
                missing_required = reverse_stats.get("missing_required_checks", [])
                if missing_required:
                    missing_required_by_image.append(
                        (Path(result["image_path"]).name, sorted(missing_required))
                    )

        if missing_required_by_image:
            print(f"\nMissing Required Field Checks ({len(missing_required_by_image)}):")
            for image_name, missing_fields in missing_required_by_image:
                print(f"  - {image_name}")
                for field in missing_fields:
                    print(f"      ✗ {field}")

        print("=" * 70)

        self.results = all_results
        return total, passed, failed


def main():
    parser = argparse.ArgumentParser(
        description="Validate metadata in ComfyUI workflow test outputs",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Windows
  python validate_metadata.py ^
    --output-folder "C:\\StableDiffusion\\StabilityMatrix-win-x64\\Data\\Packages\\ComfyUI_windows_portable\\ComfyUI\\output\\Test"

  # Linux/Mac
  python validate_metadata.py --output-folder "/path/to/ComfyUI/output/Test"

  # Custom workflow directory
  python validate_metadata.py --output-folder "./output/Test" --workflow-dir "./my_workflows"
        """,
    )

    parser.add_argument(
        "--output-folder",
        type=str,
        required=True,
        help="Path to ComfyUI output Test folder containing generated images",
    )

    parser.add_argument(
        "--workflow-dir",
        type=str,
        default="dev_test_workflows",
        help=("Directory containing workflow JSON files (default resolves to tests/comfyui_cli_tests/dev_test_workflows)"),
    )

    parser.add_argument(
        "--log-file",
        type=str,
        default=None,
        help="Path to write a copy of all console output (txt). Default: <output-folder>/validation_log.txt",
    )

    parser.add_argument(
        "--models-path",
        type=str,
        default=None,
        help="Path to ComfyUI models directory for validating hashes against .sha256 sidecar files (optional)",
    )

    parser.add_argument(
        "--verbose",
        action="store_true",
        help=(
            "Show detailed validation results including reverse validation checks. "
            "Prints each metadata field found and whether it has a corresponding validation check."
        ),
    )

    parser.add_argument(
        "--extra-workflows",
        type=str,
        default=None,
        help="Additional directory containing workflow JSON files to validate (optional)",
    )

    args = parser.parse_args()

    # Convert to absolute paths
    workflow_dir = _resolve_relative_path(args.workflow_dir, fallback=CLI_COMPAT_DIR)
    if workflow_dir is None:
        print("✗ Error: Unable to resolve workflow directory path.")
        return 1
    output_dir = Path(args.output_folder)
    models_path = Path(args.models_path) if args.models_path else None
    extra_workflows_dir = _resolve_relative_path(args.extra_workflows, fallback=CLI_COMPAT_DIR)

    # Setup logging
    # Determine log file path
    log_path = Path(args.log_file) if args.log_file else (output_dir / "validation_log.txt")
    setup_print_tee(log_path)

    # Create validator and run
    validator = MetadataValidator(workflow_dir, output_dir, models_path)
    validator.verbose = args.verbose  # Pass verbose flag to validator
    total, passed, failed = validator.run_validation(extra_workflows_dir)

    # Exit with appropriate code
    return 0 if failed == 0 and total > 0 else 1


if __name__ == "__main__":
    sys.exit(main())
